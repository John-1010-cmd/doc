---
title: 多线程 Q&A
date: 2023-05-16
updated : 2023-05-16
categories: 
- Java
tags: 
- Java
description: 这是一篇关于多线程 Q&A的Blog。
---

## Java中线程的实现方式

在Java中，线程的实现方式主要有两种：

1. 继承Thread类：可以通过继承Thread类创建线程。需要重写Thread类的run()方法，将线程的任务逻辑写在run()方法中。然后可以创建Thread的实例，并调用start()方法启动线程。

```java
class MyThread extends Thread {
    public void run() {
        // 线程的任务逻辑
    }
}

// 创建线程实例
Thread thread = new MyThread();
// 启动线程
thread.start();
```

2. 实现Runnable接口：可以通过实现Runnable接口创建线程。需要实现Runnable接口的run()方法，将线程的任务逻辑写在run()方法中。然后可以创建Thread的实例，将实现了Runnable接口的对象作为参数传入，并调用start()方法启动线程。

```java
class MyRunnable implements Runnable {
    public void run() {
        // 线程的任务逻辑
    }
}

// 创建线程实例
Runnable runnable = new MyRunnable();
Thread thread = new Thread(runnable);
// 启动线程
thread.start();
```

相比于继承Thread类，实现Runnable接口更具灵活性，因为Java中只支持单继承，而实现接口可以避免这个限制。此外，还可以使用实现Runnable接口的方式实现线程池中的多线程执行。

除了以上两种方式，还可以使用Callable接口和Future接口创建线程，这种方式可以获取线程执行结果。另外，还可以使用线程池框架（如ExecutorService）来管理和调度线程。

## Java中线程的状态

在Java中，线程具有以下几种状态：

1. 新建（New）：线程被创建但尚未启动的状态。
2. 运行（Runnable）：线程正在执行任务的状态。注意，运行状态并不代表线程一定在执行，只是表示线程具备执行的资格，可能正在等待CPU时间片分配。
3. 阻塞（Blocked）：线程因为某些原因暂时停止执行，等待某个条件满足后再继续执行。常见的情况包括线程等待锁、等待输入输出、等待其他线程的通知等。
4. 等待（Waiting）：线程因为某些原因无限期地等待另一个线程的通知。线程会调用`Object.wait()`、`Thread.join()`、`LockSupport.park()`等方法进入等待状态。
5. 超时等待（Timed Waiting）：线程因为某些原因有限期地等待另一个线程的通知。线程会调用`Thread.sleep()`、`Object.wait(long)`、`LockSupport.parkNanos()`等方法进入超时等待状态。
6. 终止（Terminated）：线程执行完任务或者出现异常而结束的状态。

线程在不同的状态之间会根据不同的操作进行转换，例如通过调用`start()`方法启动线程可以将线程从新建状态转换为运行状态，线程执行完任务会进入终止状态等。

需要注意的是，线程状态的切换并不是一成不变的，可能会受到操作系统、线程调度算法以及代码逻辑的影响。因此，在编写多线程代码时要充分考虑线程状态的变化，避免出现竞态条件和死锁等问题。

## Java中如何停止线程

在Java中停止线程有几种常见的方式：

1. 使用标志位：在线程的执行逻辑中使用一个标志位，当标志位为true时线程继续执行，当标志位为false时线程退出循环或执行完成。可以通过设置标志位来控制线程的停止。

```java
// 定义标志位
private volatile boolean flag = true;

// 在线程的执行逻辑中使用标志位
while (flag) {
    // 线程执行的逻辑
}

// 设置标志位为false，停止线程
flag = false;
```

2. 使用Thread的interrupt()方法：调用线程的`interrupt()`方法可以中断线程的执行，将线程的中断状态设置为true。被中断的线程可以根据中断状态自行处理，通常是在适当的时候退出执行。

```java
// 中断线程
thread.interrupt();

// 线程的执行逻辑中判断中断状态并处理
while (!Thread.currentThread().isInterrupted()) {
    // 线程执行的逻辑
}
```

需要注意的是，`interrupt()`方法仅仅是设置线程的中断状态，具体的中断逻辑需要线程自行处理。

3. 使用stop()方法（已过时）：`stop()`方法是Thread类中的一个方法，可以立即终止线程的执行。然而，该方法已经被标记为过时，不推荐使用。因为`stop()`方法可能会导致线程的状态不一致、资源泄漏以及不可预测的行为，容易引发安全问题。

需要谨慎使用`stop()`方法，推荐使用前两种方式来停止线程，通过合理的控制和处理逻辑来使线程自行退出。

## Java中sleep和wait方法的区别

在Java中，`sleep()`和`wait()`方法都可以用于线程的暂停，但它们在使用方式和作用上有一些区别。

1. `sleep()`方法：
   - `sleep()`方法是`Thread`类的静态方法，可以通过`Thread.sleep()`来调用。
   - `sleep()`方法使当前线程暂停执行，进入阻塞状态，并且不释放锁资源。
   - `sleep()`方法的参数是毫秒数，用于指定线程暂停的时间。
   - `sleep()`方法可能会抛出`InterruptedException`异常，需要进行处理。
2. `wait()`方法：
   - `wait()`方法是`Object`类中的方法，可以在任意对象上调用。
   - `wait()`方法使当前线程进入等待状态，同时释放对象的锁资源，使其他线程可以获取该对象的锁。
   - `wait()`方法必须在同步代码块或同步方法中调用，否则会抛出`IllegalMonitorStateException`异常。
   - `wait()`方法可以通过`notify()`或`notifyAll()`方法唤醒等待中的线程。
   - `wait()`方法可能会抛出`InterruptedException`异常，需要进行处理。

总结：
- `sleep()`方法主要用于线程的暂停，指定暂停的时间，不释放锁资源。
- `wait()`方法主要用于线程间的协作，使线程进入等待状态，释放锁资源，需要通过`notify()`或`notifyAll()`方法来唤醒等待中的线程。

需要注意的是，`sleep()`和`wait()`方法都可能抛出`InterruptedException`异常，在使用时需要适当处理异常情况。此外，`wait()`方法需要在同步代码块或同步方法中使用，并且需要注意线程间的协作关系，以免出现死锁或无法唤醒的情况。

## 并发编程的三大特性

并发编程的三大特性是原子性（Atomicity）、可见性（Visibility）和有序性（Ordering）。

1. 原子性（Atomicity）：原子性指的是一个操作是不可分割的，要么全部执行成功，要么全部不执行。在并发环境下，多个线程同时对共享资源进行操作时，原子性保证了操作的完整性，避免了数据不一致的问题。常见的原子操作包括加锁操作、CAS（Compare and Swap）操作等。
2. 可见性（Visibility）：可见性指的是当一个线程修改了共享变量的值时，其他线程能够立即看到最新的值。在多线程环境中，由于每个线程有自己的工作内存，线程之间对共享变量的修改可能不会立即同步到主内存，从而导致一个线程对共享变量的修改对其他线程不可见。为了保证可见性，可以使用`volatile`关键字或显式地使用同步机制（如`synchronized`、`Lock`等）来确保变量的可见性。
3. 有序性（Ordering）：有序性指的是程序执行的顺序按照代码的先后顺序执行，保证了程序执行的结果是符合预期的。在并发环境下，由于线程的交替执行和指令重排的存在，可能会导致代码的执行顺序发生变化，从而影响程序的正确性。为了保证有序性，可以使用同步机制（如`synchronized`、`Lock`等）或使用`volatile`关键字。

这三个特性是并发编程中非常重要的概念，合理地应用它们可以确保多线程程序的正确性和性能。在实际开发中，需要注意并发编程带来的竞态条件、死锁、数据不一致等问题，并采取相应的措施来解决这些问题。

## 什么是CAS，有什么优缺点

CAS（Compare and Swap）是一种并发控制原语，用于解决并发环境下的数据竞争问题。它是一种乐观锁的实现方式，通过比较共享变量的当前值与期望值是否相等来判断是否发生了并发冲突，从而决定是否更新共享变量的值。

CAS操作包括三个操作数：内存位置（共享变量）、期望值和新值。它的执行过程如下：
1. 读取内存位置的当前值；
2. 比较当前值与期望值是否相等；
3. 如果相等，将新值写入内存位置；
4. 如果不相等，说明其他线程已经修改了内存位置的值，操作失败。

CAS的优点：
1. 高效性：CAS操作是一条CPU原子指令，不需要加锁和解锁操作，因此具有非常高的执行效率。
2. 线程安全：CAS操作保证了线程之间的互斥性，避免了数据竞争和并发冲突。
3. 无阻塞：CAS操作是非阻塞的，如果操作失败，不会阻塞线程，而是返回失败的结果，可以根据实际需求进行相应处理。

CAS的缺点：
1. ABA问题：CAS操作在比较值时只关注当前值与期望值是否相等，没有考虑值的修改历史，因此可能出现ABA问题。即如果一个值在操作期间先后被修改为A、B，然后又被修改回A，此时CAS操作无法感知到值的变化，可能导致操作的结果不符合预期。
2. 循环时间长：如果CAS操作失败，需要重试，而重试的次数不确定，可能会导致循环时间较长，降低了效率。
3. 只能保证一个共享变量的原子操作：CAS操作只能针对一个共享变量进行原子操作，无法支持多个变量之间的原子操作。

综上所述，CAS是一种高效且线程安全的并发控制机制，适用于解决多线程环境下的数据竞争问题。然而，需要注意解决ABA问题和循环时间长的情况，以及无法支持多个变量之间的原子操作。

## @Contended注解有什么用

`@Contended` 是 Java 8 引入的一种注解，用于解决伪共享（False Sharing）的问题。伪共享是指多个线程同时访问不同的变量，但这些变量存储在同一个缓存行（Cache Line）中，由于缓存一致性协议的原因，即使只有一个变量被修改，也会导致整个缓存行的数据无效，从而造成性能下降。

`@Contended` 注解可以应用于类、字段或数组元素，用于告诉 JVM 在内存布局中对注解标记的变量进行填充，以避免伪共享。使用 `@Contended` 注解会强制 JVM 在变量的前后填充一些无关的数据，使得不同变量之间在不同的缓存行中，从而避免伪共享带来的性能问题。

需要注意的是，`@Contended` 注解在不同的 JVM 实现中可能有不同的行为，有些 JVM 可能会忽略该注解。此外，使用该注解可能会增加对象的内存消耗，因此应该根据实际情况进行评估和测试，确保它对性能的改善效果超过了可能的额外开销。

总结来说，`@Contended` 注解用于解决伪共享问题，通过对变量进行填充来避免多个变量存储在同一个缓存行中，提高多线程环境下的性能。

## Java中的四种引用类型

Java中的四种引用类型包括：

1. 强引用（Strong Reference）：最常见的引用类型，通过关键字 `new` 创建的对象默认为强引用。只要强引用存在，垃圾回收器不会回收该对象。
2. 软引用（Soft Reference）：通过 `SoftReference` 类创建的引用，用于描述一些还有用但非必需的对象。当系统内存不足时，垃圾回收器会根据内存需求来决定是否回收软引用对象。
3. 弱引用（Weak Reference）：通过 `WeakReference` 类创建的引用，用于描述一些非必需的对象。在垃圾回收时，无论内存是否充足，弱引用都会被立即回收。
4. 虚引用（Phantom Reference）：通过 `PhantomReference` 类创建的引用，用于描述一些即将被回收的对象。虚引用的主要作用是跟踪对象被垃圾回收的状态，无法通过虚引用访问对象的任何属性或方法。

这些引用类型在内存管理和垃圾回收过程中有不同的行为和特点，可以根据实际需求选择适合的引用类型来控制对象的生命周期和回收行为。

## ThreadLocal的内存泄漏问题

在使用 `ThreadLocal` 的过程中，如果没有正确地进行清理操作，可能会导致内存泄漏问题。

`ThreadLocal` 使用一个特殊的线程副本来存储数据，每个线程都有自己的副本，线程之间的数据不会相互干扰。当一个线程完成任务后，如果没有显式地删除 `ThreadLocal` 对象的引用，那么该 `ThreadLocal` 对象及其关联的副本将会被保留在内存中，而不会被垃圾回收。

如果长时间持有 `ThreadLocal` 对象的引用，而不释放它们，就会导致内存泄漏问题。特别是在使用线程池的情况下，线程对象可能会被重复使用，而 `ThreadLocal` 对象却一直保留在内存中，从而占用了大量的内存空间。

为了避免 `ThreadLocal` 的内存泄漏问题，需要在使用完毕后进行适当的清理操作。可以通过 `remove()` 方法手动删除 `ThreadLocal` 对象的引用，或者使用 `ThreadLocal` 的 `initialValue()` 方法设置一个初始值，在使用完毕后自动清理。

另外，使用 `ThreadLocal` 时，应尽量避免强引用的使用，将 `ThreadLocal` 对象设置为弱引用或使用 `WeakReference` 包装，以便在不再需要时能够更容易地被垃圾回收。

## Java中锁的分类

在Java中，锁可以分为以下几种分类：

1. **内置锁（Intrinsic Lock）**：也称为监视器锁（Monitor Lock）或synchronized锁。它是Java中最基本的锁机制，使用`synchronized`关键字来实现。内置锁是针对对象的，每个对象都有一个内置锁，它用于实现对象级别的同步。
2. **重入锁（Reentrant Lock）**：`java.util.concurrent.locks.ReentrantLock`是Java提供的可重入锁实现。它与内置锁类似，但提供了更灵活的锁定机制，可以显式地获取和释放锁，并支持公平性和可中断性等特性。
3. **读写锁（ReadWrite Lock）**：`java.util.concurrent.locks.ReadWriteLock`是Java提供的一种特殊的锁机制，它分为读锁和写锁。读锁可以被多个线程同时持有，而写锁只能被一个线程持有。读写锁适用于读多写少的场景，可以提高并发性能。
4. **自旋锁（Spin Lock）**：自旋锁是一种忙等待的锁，线程不会被挂起，而是反复检查锁的状态，直到获取到锁为止。自旋锁适用于锁定时间很短的情况，避免线程切换的开销。
5. **条件锁（Condition Lock）**：`java.util.concurrent.locks.Condition`接口提供了条件锁的机制，它可以让线程在特定条件下等待或唤醒。条件锁通常与重入锁配合使用，可以实现更复杂的线程同步和通信。
6. **阻塞队列（Blocking Queue）**：阻塞队列是一种特殊的锁机制，它可以实现线程之间的安全数据传输。线程可以通过阻塞队列的操作进行数据的存入和取出，在队列为空或满时会被阻塞，直到条件满足。

这些锁机制在不同的场景下有各自的适用性，根据具体的需求和性能要求选择合适的锁机制可以提高程序的并发性和线程安全性。

## synchronized在JDK1.6中的优化

在 JDK 1.6 中，对 synchronized 进行了一些优化，主要包括以下两个方面：

1. **锁粗化（Lock Coarsening）**：JVM 在编译阶段会对连续的加锁和解锁操作进行优化，将多个连续的加锁解锁操作合并为一个更大的锁范围，减少锁的粒度，从而减少了加锁和解锁的开销。
2. **锁消除（Lock Elimination）**：JVM 在 JIT 编译阶段通过逃逸分析技术判断对象的使用范围，如果一个对象被确定为不会逃逸到其他线程中，那么就可以安全地消除加锁操作，因为在单线程环境下是不需要加锁保护的。

锁粗化和锁消除的优化手段主要针对一些频繁的加锁解锁操作或者确定不需要加锁的场景，通过减少锁的粒度或消除不必要的锁，可以提高程序的并发性能和效率。

需要注意的是，这些优化是由 JVM 自动进行的，无需开发人员手动干预。在实际开发中，我们应该关注代码的编写和设计，避免不必要的锁竞争和频繁的加锁解锁操作，以提高代码的性能和并发能力。

## synchronized的实现原理

synchronized 是 Java 中的关键字，用于实现线程之间的同步和互斥。它可以修饰方法和代码块，用来控制对共享资源的访问。

synchronized 的实现原理主要涉及到对象监视器（Monitor）和内置锁（Intrinsic Lock）。

1. **对象监视器**：每个 Java 对象都与一个对象监视器相关联，它是对象头的一部分。对象监视器负责管理对象的锁状态、线程等待队列和线程的阻塞唤醒等机制。
2. **内置锁**：synchronized 使用内置锁实现同步。每个对象监视器都有一个与之关联的内置锁，也称为监视器锁。在进入 synchronized 修饰的方法或代码块时，线程会自动获取内置锁。当线程释放锁时，其他线程才能获取该锁。

synchronized 的工作过程如下：

- 当线程进入 synchronized 修饰的方法或代码块时，它会尝试获取内置锁。
- 如果内置锁没有被其他线程占用，则当前线程获得锁，并可以继续执行临界区代码。
- 如果内置锁已经被其他线程持有，则当前线程进入阻塞状态，被放入锁的等待队列中，等待获取锁的机会。
- 当持有锁的线程释放锁时，JVM 会从等待队列中选择一个线程唤醒，被唤醒的线程重新尝试获取锁。

synchronized 的实现保证了多线程访问共享资源的互斥性和可见性，确保了线程之间的顺序执行和数据的一致性。它是 Java 中常用的线程同步机制之一。

## 什么是AQS

AQS（AbstractQueuedSynchronizer）是 Java 并发包中的一个抽象类，用于构建同步器（Synchronizer）的基础框架。AQS 提供了一套用于构建阻塞式同步器的底层算法和模板方法，它是许多同步类（如 ReentrantLock、Semaphore、CountDownLatch 等）的基础。

AQS 的主要作用是定义了一种同步器的设计模式，通过继承 AQS 并实现其中的抽象方法，可以方便地构建自定义的同步器。它提供了一种基于状态的同步机制，通过内置的队列（CLH 队列）来管理线程的阻塞和唤醒，实现线程之间的同步与协作。

AQS 的核心思想是使用一个整型的状态值来表示同步器的状态，通过获取和释放状态来实现线程的阻塞和唤醒。AQS 内部维护一个等待队列，用于存放被阻塞的线程，线程在获取不到同步状态时会被阻塞并加入等待队列，当同步状态可用时，AQS 会从队列中选择一个线程唤醒。

AQS 提供了两种方式来支持同步器的实现：独占模式和共享模式。独占模式是指同一时间只允许一个线程持有同步状态，如 ReentrantLock；共享模式是指允许多个线程同时持有同步状态，如 CountDownLatch。

通过使用 AQS，开发人员可以更加灵活地构建自定义的同步组件，实现对共享资源的高效管理和控制。AQS 是 Java 并发包中非常重要的一个组件，它在实现锁、条件变量、信号量等同步类时起到了核心的作用。

## AQS唤醒节点时，为何从后往前找

AQS（AbstractQueuedSynchronizer）在唤醒节点时从后往前找是为了确保公平性和有序性。

AQS 内部维护了一个等待队列，用于存放被阻塞的线程节点（Node）。这些节点按照线程进入等待状态的顺序排列，新的节点会被追加到队列的尾部。

当需要唤醒节点时，AQS 会从等待队列的头部开始，依次遍历节点，查找符合唤醒条件的节点。为什么要从后往前找呢？

这是因为 AQS 使用了一种双向链表的数据结构来组织等待队列，每个节点都有一个指向前一个节点的引用。这种双向链表的结构使得从后往前遍历更加高效，可以减少遍历的次数。

此外，从后往前找也可以保证公平性。公平性是指多个线程按照申请资源的顺序来获取锁或许可，避免饥饿现象。如果从前往后找，先进入等待队列的线程可能会一直等待下去，无法获得执行的机会。而从后往前找，可以保证较早进入等待队列的线程更有机会被唤醒，增加了公平性。

因此，AQS 从后往前找是为了提高效率和保证公平性，确保等待队列中的线程按照先后顺序被唤醒。这种唤醒方式在实现锁、条件变量等同步组件时非常重要，可以有效地管理线程的阻塞和唤醒。

## ReentrantLock和synchronized的区别

ReentrantLock和synchronized是Java中用于实现线程同步的两种机制，它们有以下区别：

1. 可重入性：ReentrantLock是可重入锁，也就是说同一个线程可以多次获得同一个锁，而synchronized是可重入的。当线程已经获得了synchronized锁之后，可以再次进入被该锁保护的代码块，而不会被阻塞。这种特性对于一些递归或嵌套的代码结构很有用。
2. 锁的获取方式：ReentrantLock提供了两种获取锁的方式，即公平锁和非公平锁，而synchronized是非公平锁。公平锁会按照线程请求锁的顺序来获取锁，而非公平锁则允许线程插队获取锁。这意味着在高并发情况下，ReentrantLock可以通过公平锁来避免某些线程长时间等待的情况。
3. 锁的释放方式：ReentrantLock需要手动释放锁，即在使用完锁之后，需要调用unlock()方法显式释放锁。而synchronized在代码块执行完毕或异常抛出时会自动释放锁，无需手动处理。
4. 条件变量：ReentrantLock提供了Condition对象，可以通过它来实现更灵活的线程通信和控制，而synchronized没有提供类似的功能。
5. 性能：在低并发的情况下，synchronized的性能通常比ReentrantLock好，因为synchronized是JVM级别的内置特性，而ReentrantLock需要额外的方法调用和状态维护。

总的来说，ReentrantLock相比于synchronized提供了更多的功能和灵活性，但使用时需要注意手动释放锁和选择合适的获取方式。对于简单的同步需求，synchronized已经足够，并且更简单易用。对于更复杂的同步场景，或者需要更细粒度的控制和更高的性能，可以选择使用ReentrantLock。

## ReentrantReadWriteLock的实现原理

ReentrantReadWriteLock是Java中用于实现读写锁的类，它提供了在读操作和写操作之间进行线程同步的机制。其实现原理主要包括以下几个关键点：

1. 锁的类型：ReentrantReadWriteLock内部维护了两种类型的锁，即读锁和写锁。多个线程可以同时获取读锁，但只能有一个线程获取写锁。当写锁被占用时，任何线程都无法获取读锁或写锁。
2. 重入性：ReentrantReadWriteLock是可重入的，也就是说线程可以多次获取同一个锁。
3. 锁的获取顺序：当有线程请求写锁时，会阻塞其他线程的读锁和写锁获取。而当有线程请求读锁时，只会阻塞其他线程的写锁获取，而对于读锁的获取是可以并发进行的。
4. 写锁降级：ReentrantReadWriteLock支持写锁的降级，即一个线程在持有写锁的情况下，可以再获取读锁，然后释放写锁。这样可以保证在某个线程进行写操作期间，其他线程仍可以并发进行读操作。
5. 公平性：ReentrantReadWriteLock提供了公平锁和非公平锁的选择。公平锁会按照线程请求锁的顺序进行获取，而非公平锁允许线程插队获取锁。

总的来说，ReentrantReadWriteLock通过维护读锁和写锁的状态，以及相应的获取和释放规则，实现了读写操作之间的线程同步。它在高并发读操作、少量写操作的场景下，能够提供更好的性能和吞吐量。但需要注意合理使用，避免出现死锁或竞争条件的情况。

## JDK中提供了哪些线程池

JDK中提供了以下几种线程池：

1. `FixedThreadPool`: 固定大小线程池，创建一个固定大小的线程池，任务提交后会在池中创建固定数量的线程进行执行。
2. `CachedThreadPool`: 缓存线程池，可以根据需要自动创建新线程，空闲线程会被保留一段时间后回收，适用于执行大量短期任务的场景。
3. `SingleThreadExecutor`: 单线程线程池，只会创建一个线程来执行任务，保证所有任务按顺序执行。
4. `ScheduledThreadPool`: 定时任务线程池，可以按指定的延迟或固定的时间间隔周期性地执行任务。
5. `WorkStealingPool`: 工作窃取线程池，适用于处理大量耗时较长的任务，它采用"工作窃取"的方式，使空闲线程从忙碌线程的任务队列中窃取任务来执行，以提高线程利用率。

这些线程池都是通过`java.util.concurrent.Executors`类提供的静态方法来创建的，使用线程池可以更好地管理和复用线程资源，提高程序的性能和效率。根据不同的场景和需求，选择合适的线程池可以更好地满足应用程序的要求。

## 线程池的核心参数有哪些

线程池的核心参数包括以下几个：

1. `corePoolSize`：核心线程数，指定了线程池中保留的线程数量，即使这些线程处于空闲状态也不会被回收。
2. `maximumPoolSize`：最大线程数，指定了线程池中允许创建的最大线程数量。
3. `keepAliveTime`：线程空闲时间，当线程池中的线程数量超过核心线程数时，多余的空闲线程会被回收，直到线程池中的线程数量等于核心线程数。`keepAliveTime`指定了非核心线程的空闲时间，超过这个时间就会被回收。
4. `unit`：空闲时间的单位，可以是秒、毫秒等。
5. `workQueue`：任务队列，用于存放待执行的任务。线程池的线程会从任务队列中取出任务进行执行。
6. `threadFactory`：线程工厂，用于创建线程。可以自定义线程工厂来对线程进行一些自定义设置，例如设置线程的名称、优先级等。
7. `rejectedExecutionHandler`：拒绝策略，当线程池无法接受新任务时，采取的处理策略。常见的策略包括抛出异常、丢弃任务、丢弃最旧的任务等。

这些核心参数可以根据实际需求进行配置，以满足不同的并发需求和资源限制。

## 线程池的状态

线程池的状态可以分为以下几种：

1. Running（运行状态）：线程池处于正常运行状态，可以接收新任务并处理已有任务。
2. Shutdown（关闭状态）：线程池处于关闭状态，不再接收新任务，但会继续处理已有任务。已提交的任务会继续执行，但不会接受新的任务提交。
3. Stop（停止状态）：线程池处于停止状态，不再接收新任务，也不会处理已有任务。正在执行的任务会被中断，未执行的任务会被丢弃。
4. Tidying（整理状态）：线程池正在执行关闭操作，正在执行关闭过程中的一些清理工作。
5. Terminated（终止状态）：线程池处于终止状态，所有任务已完成，线程池彻底终止。

线程池的状态会随着不同的操作和调用而变化。例如，当调用`shutdown()`方法时，线程池的状态会从Running转变为Shutdown；当所有任务执行完成后，线程池的状态会最终变为Terminated。

## 线程池的执行流程

线程池的执行流程如下：

1. 创建线程池：根据需要的线程数量和其他参数，创建一个线程池对象，例如通过`ExecutorService`的工厂方法创建`ThreadPoolExecutor`。
2. 提交任务：将需要执行的任务提交到线程池中，可以使用`execute()`方法或`submit()`方法提交任务。任务可以是`Runnable`接口的实现类或`Callable`接口的实现类。
3. 线程分配任务：线程池根据内部的调度算法，将提交的任务分配给空闲的线程执行。如果所有线程都正在执行任务，则任务会进入等待队列等待执行。
4. 任务执行：线程执行任务的具体逻辑，执行`Runnable`接口的`run()`方法或`Callable`接口的`call()`方法。
5. 任务完成：任务执行完毕后，线程会将结果返回或通知线程池任务已完成。
6. 回收线程：线程池会根据配置的策略决定是否回收线程。如果线程池中的线程数量超过最小线程数，并且线程处于空闲状态一定时间，则可能会被回收。
7. 线程池关闭：当不再需要线程池时，可以调用`shutdown()`方法或`shutdownNow()`方法来关闭线程池。关闭线程池会停止接收新任务，并等待已提交的任务执行完成。
8. 线程池终止：当所有任务都执行完成后，线程池终止，释放所有资源。

以上是线程池的基本执行流程，具体的流程和行为还受到线程池的配置参数、任务调度策略等因素的影响。

## 线程池添加工作线程的流程

线程池添加工作线程的流程如下：

1. 检查线程池状态：在添加工作线程之前，线程池会先检查自身的状态，例如是否已经关闭或正在关闭。如果线程池已经关闭，则不会添加新的工作线程。
2. 判断是否需要创建新的工作线程：线程池会根据当前的线程数量、活跃线程数、等待队列的长度等因素判断是否需要创建新的工作线程。具体的条件判断由线程池的实现类决定，例如`ThreadPoolExecutor`类中的`corePoolSize`和`maximumPoolSize`参数会影响是否创建新的工作线程。
3. 创建工作线程：如果确定需要创建新的工作线程，线程池会创建一个新的线程，并将其加入到线程池中。创建线程时，可以使用线程工厂（`ThreadFactory`）来创建线程对象，以便自定义线程的属性和命名。
4. 启动工作线程：创建好的工作线程会启动，并开始执行线程的任务。任务的具体逻辑由线程池提交的任务决定，可以是`Runnable`接口的实现类或`Callable`接口的实现类。
5. 记录工作线程：线程池会记录已添加的工作线程，以便管理和监控线程池的状态和性能。

添加工作线程的流程可能会受到线程池的具体实现和配置参数的影响。不同的线程池实现可能对线程的创建、启动和管理有不同的策略和行为。

## 线程池为何要构建空任务的非核心线程

线程池在构建空任务的非核心线程时，主要有两个原因：

1. 保持线程池的活跃性：线程池的目标是合理利用线程资源，提高任务的执行效率。当线程池中的核心线程数已满，并且任务队列也已满时，线程池会构建非核心线程来处理新提交的任务，以保持线程池的活跃性。即使没有实际任务需要执行，构建空任务的非核心线程也可以防止线程池因无可用线程而无法接受新任务。
2. 控制线程池的线程数量：线程池通常会根据实际需求动态调整线程数量。通过构建空任务的非核心线程，线程池可以预留一部分线程资源，以便在任务量突然增加时能够快速响应。这样可以避免线程池在短时间内频繁地创建和销毁线程，提高线程的重用性和效率。

需要注意的是，构建空任务的非核心线程并不代表线程池中的线程一定会一直空闲下来，而是为了保持线程池的灵活性和响应能力，以适应任务的动态变化。线程池会根据任务的实际情况自动调整线程数量，并通过线程池的策略和配置参数来控制线程的创建和销毁。

## 线程池使用完毕为何必须shutdown()

在使用完毕后，调用线程池的 `shutdown()` 方法是为了正确地关闭线程池。这是因为线程池内部会创建和管理一组线程，并且这些线程是通过后台线程来执行任务的。如果不正确地关闭线程池，可能会导致以下问题：

1. 阻塞应用程序的关闭：如果线程池没有被显式关闭，那么线程池中的线程将一直保持活跃状态，阻塞应用程序的正常关闭。这可能会导致应用程序无法优雅地停止，造成资源泄漏或其他异常情况。
2. 线程资源的浪费：如果不关闭线程池，线程池中的线程将一直存在，占用系统资源。特别是对于长时间运行的应用程序，未关闭的线程池可能会导致系统资源耗尽，影响系统的稳定性和性能。
3. 避免内存泄漏：线程池中的线程持有对应用程序资源的引用，如果线程池没有正确关闭，这些线程可能会导致资源的泄漏，进而造成内存泄漏问题。

因此，为了确保应用程序的正常关闭和资源的释放，使用完毕后应该显式调用线程池的 `shutdown()` 方法来关闭线程池。该方法会按照一定的规则停止接受新的任务，并尝试优雅地关闭线程池中的线程，确保所有已提交的任务都得到执行，并释放相关的资源。

## 线程池的核心参数到底如何设置

设置线程池的核心参数需要根据应用程序的需求和系统资源进行评估和调整。以下是一些常见的线程池核心参数及其设置建议：

1. 核心线程数（corePoolSize）：表示线程池中保持活跃的线程数量。根据应用程序的并发量和系统资源情况，可以根据经验或性能测试来确定合适的值。一般建议设置为处理器核心数的两倍或更少，以充分利用系统资源。
2. 最大线程数（maximumPoolSize）：表示线程池中允许创建的最大线程数量。根据应用程序的并发需求和系统资源情况，可以根据经验或性能测试来确定合适的值。通常，最大线程数要大于或等于核心线程数，以便在高负载时可以创建额外的线程来处理任务。
3. 阻塞队列（workQueue）：用于存放待执行任务的队列。可以选择不同类型的阻塞队列，如无界队列（如 `LinkedBlockingQueue`）或有界队列（如 `ArrayBlockingQueue`）。选择合适的队列类型取决于应用程序的需求和内存资源。
4. 空闲线程存活时间（keepAliveTime）：指的是当线程池中的线程数量超过核心线程数时，多余的空闲线程在多长时间内保持存活状态。根据应用程序的特点和响应时间需求，可以设置适当的空闲线程存活时间。
5. 线程工厂（threadFactory）：用于创建线程的工厂类。可以使用默认的线程工厂（如 `Executors.defaultThreadFactory()`）或自定义的线程工厂，根据需要设置。

设置线程池的核心参数需要综合考虑应用程序的并发需求、系统资源以及性能要求。可以通过性能测试和监控来调整参数，以达到最佳的线程池配置。

## ConcurrentHashMap在1.8做了什么优化

在 Java 8 中，ConcurrentHashMap 进行了一系列的优化，以提高并发性能和减少锁竞争。以下是 Java 8 中 ConcurrentHashMap 的优化内容：

1. 分段锁替换为 CAS+Synchronized：在 Java 7 及之前的版本中，ConcurrentHashMap 使用分段锁来实现并发控制，即将整个散列表分为多个段，每个段拥有一个锁。而在 Java 8 中，ConcurrentHashMap 使用了更细粒度的锁机制，即 CAS（Compare and Swap）和 Synchronized 的组合，减少了锁的竞争，提高了并发性能。
2. 锁粒度的细化：Java 8 中对锁的粒度进行了细化，将锁的粒度从整个段（Segment）细化为每个链表或红黑树节点，使得只有访问同一节点的线程才会发生竞争，提高了并发性能。
3. 数据结构的改进：Java 8 中的 ConcurrentHashMap 采用了新的数据结构，即数组 + 链表 + 红黑树的组合，以更好地支持高并发场景。当链表长度超过阈值时，链表会转换为红黑树，提高了查找和插入的效率。
4. CAS+Synchronized 的操作顺序：Java 8 中将 CAS 操作和 Synchronized 块的顺序进行了优化，使得大多数情况下只需进行一次 CAS 操作，减少了不必要的竞争。
5. 增强了迭代器的弱一致性：Java 8 中的 ConcurrentHashMap 迭代器提供了更好的弱一致性保证，避免了迭代过程中出现的 ConcurrentModificationException 异常。

通过这些优化，Java 8 中的 ConcurrentHashMap 在并发性能和线程安全性方面有了显著的提升，更适用于高并发的场景。

## ConcurrentHashMap的散列算法

ConcurrentHashMap 的散列算法是通过对键的 hashCode 进行一系列操作得到最终的散列值。在 Java 8 及之前的版本中，ConcurrentHashMap 使用的散列算法是基于传统的哈希桶和链表结构，而在 Java 8 中引入了红黑树结构，以提高性能。

具体的散列算法如下：

1. 初始散列值：根据键的 hashCode 值进行初始化，通常是直接使用键的 hashCode() 方法返回的值。
2. 散列扰动（Spread）：将初始散列值通过扰动函数进行扰动，以减少哈希冲突。扰动函数的具体实现为 `(h ^ (h >>> 16)) & HASH_BITS`，其中 `h` 是初始散列值，`>>>` 表示无符号右移，`HASH_BITS` 是一个常量用于限制散列值的位数。
3. 确定桶索引：根据扰动后的散列值确定键在哈希表中的桶索引。对于默认的并发级别（16），使用 `hash & (table.length - 1)` 来确定桶索引，其中 `table.length` 是哈希表的长度。
4. 桶为空：如果确定的桶为空，表示没有发生哈希冲突，可以直接将键值对插入该桶。
5. 桶非空：如果确定的桶非空，表示发生了哈希冲突。对于 Java 8 及之前的版本，采用链表结构来解决冲突，将键值对插入链表的末尾。对于 Java 8 及之后的版本，如果链表长度超过阈值（默认为 8），将链表转换为红黑树，以提高查找和插入的效率。

通过散列算法和相应的冲突解决机制，ConcurrentHashMap 能够高效地处理并发场景下的键值对操作，并提供较好的性能和线程安全性。

## ConcurrentHashMap初始化数组的流程

ConcurrentHashMap 在初始化时会创建一个初始容量大小的数组作为哈希表，具体的初始化流程如下：

1. 创建空数组：首先，根据指定的初始容量和加载因子（默认为 0.75），创建一个空的 Entry 数组。初始容量是指哈希表中桶的数量，加载因子是指当哈希表中的元素数量达到容量与加载因子的乘积时，会触发扩容操作。
2. 分段锁数组：ConcurrentHashMap 会根据指定的并发级别（默认为 16）创建相应数量的分段锁（Segment）。每个分段锁负责保护哈希表中一部分桶的操作，通过对哈希值进行分段操作，不同的键值对可以并发地操作不同的分段锁，从而提高并发性能。
3. 初始化每个分段：对于每个分段，会创建一个空的 HashEntry 数组作为该分段的哈希表。每个 HashEntry 表示一个桶，用于存储键值对。
4. 哈希表的链接：将每个分段的哈希表链接到整个 ConcurrentHashMap 中，形成一个完整的哈希表。

在初始化完成后，ConcurrentHashMap 就可以开始进行并发的键值对操作了。通过分段锁的机制，不同的线程可以同时操作不同的分段，提高了并发性能，并且每个分段的操作都是线程安全的。当插入、删除或查找键值对时，会根据键的散列值定位到相应的分段，并在该分段的哈希表中执行相应的操作。

## ConcurrentHashMap扩容的流程

ConcurrentHashMap 在需要扩容时，会执行以下流程：

1. 计算新的容量：当哈希表中的元素数量达到容量与加载因子的乘积时，就会触发扩容操作。首先会根据当前容量（Capacity）和加载因子（Load factor）计算出新的容量（newCap）和阈值（threshold）。
   - 新容量 newCap 的计算是将当前容量（Capacity）翻倍，并找到不小于新容量的最小的 2 的幂次方。
   - 新阈值 threshold 的计算是根据新容量和加载因子的乘积得出。
2. 创建新的哈希表：根据新的容量，创建一个新的 Entry 数组作为扩容后的哈希表。
3. 数据迁移：遍历原有的哈希表，将其中的键值对重新计算哈希值，并放入新的哈希表中的对应位置。这一过程需要确保在迁移期间，其他并发操作不受影响，所以需要使用分段锁来保护各自的分段。
4. 更新引用：将 ConcurrentHashMap 的内部数据结构指向新的哈希表，完成扩容操作。

在扩容期间，原有的哈希表仍然可以接收并处理读取操作，但写入操作需要等到扩容完成之后才能执行。扩容过程中的读取操作可以通过跨两个哈希表来进行，以确保数据的可见性和一致性。

扩容操作可以提高 ConcurrentHashMap 的并发能力，减少冲突，提高性能。然而，扩容操作也会消耗一定的时间和资源，所以在设计 ConcurrentHashMap 时，需要合理设置初始容量和加载因子，以减少扩容的次数。

## ConcurrentHashMap读取数据的流程

ConcurrentHashMap 在读取数据时的流程如下：

1. 计算键的哈希值：根据键对象的哈希算法，计算出键的哈希值。
2. 定位到段（Segment）：ConcurrentHashMap 内部使用了分段锁（Segment）的机制来保护并发访问，每个段维护了一个独立的哈希表。根据哈希值，确定要访问的段的索引。
3. 获取段的锁：通过获取段的锁，保证对该段的并发操作的互斥性。不同的线程可以同时访问不同的段，以提高并发性能。
4. 在段的哈希表中查找：在获取到段的锁之后，通过哈希值再次计算出在该段的哈希表中的索引位置。
5. 遍历链表或红黑树：由于可能存在哈希冲突，一个索引位置可能对应多个键值对。对于哈希冲突的情况，ConcurrentHashMap 使用链表或红黑树来解决。根据具体情况，遍历链表或红黑树，在其中查找匹配的键。
6. 返回结果：如果找到了匹配的键，返回相应的值；如果未找到匹配的键，返回 null。

在读取数据时，ConcurrentHashMap 可以支持并发读取操作，不需要加锁，提高了并发性能。不同的线程可以同时读取不同的段，以避免对整个 ConcurrentHashMap 加锁造成的性能瓶颈。

## ConcurrentHashMap中计数器的实现

在 Java 8 及之后的版本中，ConcurrentHashMap 中的计数器采用了基于 CounterCell 的实现。CounterCell 是一个类似于原子整型的数据结构，它被用来存储每个段（Segment）中的计数值。

在 ConcurrentHashMap 中，每个段（Segment）都维护了一个 CounterCell 数组，用于存储计数器的值。每个 CounterCell 是一个独立的计数器，它包含一个整型的计数值。

在更新计数器时，会首先尝试原子地增加计数器的值。如果这个操作成功了，那么就直接返回。但是如果存在竞争，多个线程同时更新同一个计数器，那么就会创建新的 CounterCell，并使用 CAS（Compare and Set）操作将其存储到段中的 CounterCell 数组中。这样就可以保证每个线程都有一个独立的计数器来进行计数。

CounterCell 的实现采用了一种细粒度的锁机制，即使用了 Striping Lock（分段锁）的思想，每个 CounterCell 都有自己的锁，不同的 CounterCell 之间可以并发更新，提高了并发性能。

这种基于 CounterCell 的计数器实现方式，在高并发环境下可以减少竞争，提高了性能。每个线程可以独立访问自己所负责的 CounterCell，避免了对整个计数器的全局同步。