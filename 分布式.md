---
title: 分布式
date: 2023-04-27
updated : 2023-04-30
categories: 
- 分布式
tags: 
- Spring Cloud Euerka
- Spring Cloud Nacos
- Dubbo
- Zookeeper
- 一致性算法
- 分布式锁
- 分布式事务
description: 这是显示在首页的概述，正文内容均会被隐藏。
---

## Spring Cloud Netflex

### Euerka实现单点注册中心

#### 创建Eureka注册中心

```xml
<dependencyManagement>
 <dependencies>
   <dependency>
     <groupId>org.springframework.cloud</groupId>  
     <artifactId>spring-cloud-dependencies</artifactId>  
     <version>Finchley.SR2</version>  
     <type>pom</type>  
     <scope>import</scope>
   </dependency>
 </dependencies>
</dependencyManagement>
<!-- 最新版的 eureka 服务端包 -->
<dependency>
 <groupId>org.springframework.cloud</groupId>  
 <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>
<!-- 监控管理 -->
<dependency>
 <groupId>org.springframework.boot</groupId>  
 <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

```yaml
## bootstrap.yml
spring:
application:
  name: kite-eureka-center
cloud:
  inetutils: # 网卡设置
    ignoredInterfaces:  # 忽略的网卡
      - docker0
      - veth.*
      - VM.*
    preferredNetworks:  # 优先的网段
      - 192.168
```

```yaml
## application.yml
server:
port: 3000
eureka:
instance:
  hostname: eureka-center
  appname: 注册中心
client:
  registerWithEureka: false # 单点的时候设置为 false 禁止注册自身
  fetchRegistry: false
  serviceUrl:
    defaultZone: http://localhost:3000/eureka
server:
  enableSelfPreservation: false
  evictionIntervalTimerInMs: 4000
```

bootstrap.yml 和 application.yml 的区别：

- bootstrap.yml 在 application.yml 之前启动；
- bootstrap.yml 配置 application 的 name、spring.cloud.config.server.git.uri、一些encryption/decryption（加密/解密）信息；
- application.yml 的信息会覆盖 bootstrap.yml 中的内容，当遇到相同的配置的时候；

```java
@EnableEurekaServer
@SpringBootApplication
public class Application {
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

#### 创建服务提供者

```xml
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<!-- eureka 客户端 -->
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

```yaml
## application.yml
server:
port: 3001
eureka:
instance:
  preferIpAddress: true
client:
  serviceUrl:
    defaultZone: http://localhost:3000/eureka  # 注册到 eureka
spring:
application:
  name: single-provider  # 应用程序名称，后面会在消费者中用到
```

```java
@Slf4j
@RestController
public class ProviderController {
   @Autowired
   private DiscoveryClient discoveryClient;
   @RequestMapping(value = "/hello")
   public String hello(){
       List<String> services = discoveryClient.getServices();
       for(String s : services){
           log.info(s);
      }
       return "hello spring cloud!";
  }
   @RequestMapping(value = "/nice")
   public String nice(){
       List<String> services = discoveryClient.getServices();
       for(String s : services){
           log.info("gogogo" + s);
      }
       return "nice to meet you!";
  }
}
```

```java
@EnableEurekaClient
@SpringBootApplication
public class SingleProviderApplication {
   public static void main(String[] args) {
       SpringApplication.run(SingleProviderApplication.class, args);
  }
}
```

#### 创建服务消费者

```xml
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

```yaml
## application.yml
server:
port: 3002
eureka:
client:
  serviceUrl:
    defaultZone: http://127.0.0.1:3000/eureka  # 注册到 eureka
instance:
  preferIpAddress: true
spring:
application:
  name: single-customer  
```

开始消费提供者提供的服务接口，这里演示了两种消费方法，一种是用 RestTemplate ，另外一种是用 FeignClient，Feign 同样是 Netflix 开源，并被 Spring Cloud 封装到 spring-cloud-starter-openfeign 包中。

```java
@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients
public class SingleCustomerApplication {
   /**
    * 注入 RestTemplate
    * 并用 @LoadBalanced 注解，用负载均衡策略请求服务提供者
    * 这是 Spring Ribbon 的提供的能力
    * @return
    */
   @LoadBalanced
   @Bean
   public RestTemplate restTemplate() {
       return new RestTemplate();
  }
   public static void main(String[] args) {
       SpringApplication.run(SingleCustomerApplication.class, args);
  }
}
```

```java
/**
* IHelloService
* 配置服务提供者：single-provider 是服务提供者的 application.name
*/
@FeignClient("single-provider")
public interface IHelloService {
   @RequestMapping(value = "/hello")
   String hello();
   @RequestMapping(value = "nice")
   String nice();
}
```

```java
@RestController
public class ConsumerController {
   @Autowired
   private RestTemplate restTemplate;
   @Autowired
   private IHelloService helloService;
   private static final String applicationName = "single-provider";
   @RequestMapping(value = "feignRequest")
   public Object feignRequest(){
       String s = helloService.nice();
       return s;
  }
   @RequestMapping(value = "commonRequest")
   public Object commonRequest(){
       String url = "http://"+ applicationName +"/hello";
       String s = restTemplate.getForObject(url,String.class);
       return s;
  }
}
```

### Euerka实现高可用服务发现注册中心

#### 创建注册中心

```yaml
## bootstrap.yml
spring:
  application:
    name: eureka-ha-center  # 设置应用的名称
cloud:
  inetutils:
    ignoredInterfaces:
      - docker0
      - veth.*
      - VM.*
    preferredNetworks:
      - 192.168
```

```yaml
## application.yml
spring:
   profiles: eureka-center1
server:
  port: 1989
eureka:
  instance:
    hostname: ha-eureak-center1
    appname: 注册中心
  client:
    registerWithEureka: true
    fetchRegistry: true
    serviceUrl:
      defaultZone: http://localhost:1988/eureka # 注册到 eureka-center2 上，端口1988
---
spring:
  profiles: eureka-center2
server:
  port: 1988
eureka:
  instance:
    hostname: ha-eureak-center2
    appname: 注册中心
  client:
    registerWithEureka: true  
    fetchRegistry: true
    serviceUrl:
      defaultZone: http://localhost:1989/eureka  ## 注册到 eureka-center1 上，端口1989
```

通过 profiles 参数，稍后在启动的时候根据 vm 参数决定启用配置。

client.registerWithEureka 和 client.registerWithEureka 设置为 true，表示要注册到 eureka 。单点模式中设置为 false。高可用版本要允许注册到 eureka 。注意：eureka-center1 和 eureka-center2 的 serviceUrl.defaultZone 是互相注册的。

#### 创建服务提供者

```yaml
## application.yml
spring:
  profiles: ha-provider1
application:
  name: ha-provider
security:
  user:
    name: root
    password: root
server:
  port: 1990
eureka:
  instance:
    preferIpAddress: true
  client:
    serviceUrl:
      defaultZone: http://localhost:1989/eureka,http://localhost:1988/eureka
---
spring:
  profiles: ha-provider2
application:
  name: ha-provider
security:
  user:
    name: root
    password: root
server:
  port: 1991
eureka:
  instance:
    preferIpAddress: true
  client:
    serviceUrl:
      defaultZone: http://localhost:1989/eureka,http://localhost:1988/eureka
```

#### 创建服务消费者

```yaml
## application.yml
spring:
application:
  name: ha-customer
server:
  port: 1992
eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:1989/eureka,http://localhost:1988/eureka
  instance:
    preferIpAddress: true
```

#### 为Euerka服务注册中心实现安全控制

```xml
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-security</artifactId>
</dependency>
```

```yaml
## application.yml
spring:
application:
  name: kite-eureka-center
security:
    user:
      name: test # 用户名
      password: 123456   # 密码
```

```yaml
## provider
eureka:
instance:
  statusPageUrlPath: /actuator/info
  healthCheckUrlPath: /actuator/health
  prefer-ip-address: true
client:
  register-with-eureka: true
  fetch-registry: true
  service-url:
    defaultZone: http://test:123456@localhost:3000/eureka/

## consumer same
```

### Spring Cloud Config配置中心

#### 实现简单的配置中心

##### 创建配置中心服务端

```xml
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<!-- spring cloud config 服务端包 -->
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-config-server</artifactId>
</dependency>
```

```yaml
## bootstrap.yml
spring:
application:
  name: config-single-server  # 应用名称
cloud:
    config:
      server:
        git:
          uri: https://github.com/huzhicheng/config-only-a-demo #配置文件所在仓库
          username: github 登录账号
          password: github 登录密码
          default-label: master #配置文件分支
          search-paths: config  #配置文件所在根目录
```

```yaml
## application.yml
server:
port: 3301
```

```java
@SpringBootApplication
@EnableConfigServer
public class Application {
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

> Spring Cloud Config访问规则：
>
> - /{application}/{profile}[/{label}]
> - /{application}-{profile}.yml
> - /{label}/{application}-{profile}.yml
> - /{application}-{profile}.properties
> - /{label}/{application}-{profile}.properties
>
> {application} 就是应用名称，{profile} 就是配置文件的版本，{label} 表示 git 分支，默认是 master 分支

##### 创建配置中心客户端

```xml
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<!-- spring cloud config 客户端包 -->
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-config</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

```yaml
## bootstrap.yml
spring:
profiles:
  active: dev
---
spring:
profiles: prod
application:
  name: config-single-client
cloud:
    config:
      uri: http://localhost:3301
      label: master
      profile: prod
---
spring:
profiles: dev
application:
  name: config-single-client
cloud:
    config:
      uri: http://localhost:3301
      label: master
      profile: dev
```

```yaml
## application.yml
server:
port: 3302
management:
endpoint:
  shutdown:
    enabled: false
endpoints:
  web:
    exposure:
      include: "*"
data:
env: NaN
user:
  username: NaN
  password: NaN
```

要读取配置中心的内容，需要增加相关的配置类，Spring Cloud Config 读取配置中心内容的方式和读取本地配置文件中的配置是一模一样的。可以通过 @Value 或 @ConfigurationProperties 来获取。

```java
@Data
@Component
public class GitConfig {
   @Value("${data.env}")
   private String env;
   @Value("${data.user.username}")
   private String username;
   @Value("${data.user.password}")
   private String password;
}
```

```java
@Component
@Data
@ConfigurationProperties(prefix = "data")
public class GitAutoRefreshConfig {
   public static class UserInfo {
       private String username;
       private String password;
       public String getUsername() {
           return username;
      }
       public void setUsername(String username) {
           this.username = username;
      }
       public String getPassword() {
           return password;
      }
       public void setPassword(String password) {
           this.password = password;
      }
       @Override
       public String toString() {
           return "UserInfo{" +
                   "username='" + username + '\'' +
                   ", password='" + password + '\'' +
                   '}';
      }
  }
   private String env;
   private UserInfo user;
}
```

```java
@RestController
public class GitController {
   @Autowired
   private GitConfig gitConfig;
   @Autowired
   private GitAutoRefreshConfig gitAutoRefreshConfig;
   @GetMapping(value = "show")
   public Object show(){
       return gitConfig;
  }
   @GetMapping(value = "autoShow")
   public Object autoShow(){
       return gitAutoRefreshConfig;
  }
}
```

```java
@SpringBootApplication
public class Application {
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

#### 实现自动刷新

##### refresh接口自动刷新配置

Spring Cloud Config 在项目启动时加载配置内容这一机制，导致了它存在一个缺陷，修改配置文件内容后，不会自动刷新。它提供了一个刷新机制，但是需要我们主动触发。那就是 @RefreshScope 注解并结合 actuator ，注意要引入 spring-boot-starter-actuator 包。需要在client端做修改。

```yaml
## application.yml
server:
  port: 3302
management:
  endpoint:
    shutdown:
      enabled: false
  endpoints:
    web:
      exposure:
        include: "*"

data:
  env: NaN
  user:
    username: NaN
    password: NaN
```

```java
@RestController
@RefreshScope
public class GitController {
   @Autowired
   private GitConfig gitConfig;
   @Autowired
   private GitAutoRefreshConfig gitAutoRefreshConfig;
   @GetMapping(value = "show")
   public Object show(){
       return gitConfig;
  }
   @GetMapping(value = "autoShow")
   public Object autoShow(){
       return gitAutoRefreshConfig;
  }
}
```

github 提供了一种 webhook 的方式，当有代码变更的时候，会调用设置的地址，避免每次改了配置后需要访问 refresh 接口。

##### 使用Spring Cloud Bus自动刷新多个端

> Spring Cloud Bus 将分布式系统的节点与轻量级消息代理链接。这可以用于广播状态更改（例如配置更改）或其他管理指令。一个关键的想法是，Bus 就像一个扩展的 Spring Boot 应用程序的分布式执行器，但也可以用作应用程序之间的通信渠道。

如果只有一个 client 端的话，用 webhook ，设置手动刷新都不算太费事，但是如果端比较多的话呢，一个一个去手动刷新未免有点复杂。可以借助 Spring Cloud Bus 的广播功能，让 client 端都订阅配置更新事件，当配置更新时，触发其中一个端的更新事件，Spring Cloud Bus 就把此事件广播到其他订阅端，以此来达到批量更新。

在client端添加相关的包

```xml
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-bus-amqp</artifactId>
</dependency>
```

配置文件添加RabbitMQ相关配置

```yaml
spring:
rabbitmq:
  host: localhost
  port: 32775
  username: guest
  password: guest
```

修改配置后，使用 webhook ，或者手动触发的方式 POST 请求一个 client 端的 actuator/bus-refresh 接口，就可以更新给所有端了。

#### 结合Euerka使用Spring Cloud Config

##### Euerka Server

```xml
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-security</artifactId>
</dependency>
```

```yaml
## bootstrap.yml
spring:
  application:
    name: kite-eureka-center
  security:
    user:
      name: test  # 用户名
      password: 123456   # 密码
  cloud:
    inetutils: # 网卡设置
      ignoredInterfaces:  # 忽略的网卡
        - docker0
        - veth.*
        - VM.*
      preferredNetworks:  # 优先的网段
        - 192.168
```

```yaml
## application.yml
server:
  port: 3000
eureka:
  instance:
    hostname: eureka-center
    appname: 注册中心
  client:
    registerWithEureka: false # 单点的时候设置为 false 禁止注册自身
    fetchRegistry: false
    serviceUrl:
      defaultZone: http://test:123456@localhost:3000/eureka
  server:
    enableSelfPreservation: false
    evictionIntervalTimerInMs: 4000
```

```java
@EnableEurekaServer
@SpringBootApplication
public class Application {
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

##### Spring Cloud Config服务端

```xml
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<!-- spring cloud config 服务端包 -->
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-config-server</artifactId>
</dependency>
<!-- eureka client 端包 -->
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

```yaml
## application.yml
server:
  port: 3012
eureka:
  client:
    serviceUrl:
      register-with-eureka: true
      fetch-registry: true
        defaultZone: http://test:123456@localhost:3000/eureka/
  instance:
    preferIpAddress: true
spring:
  application:
    name: config-eureka-server
  cloud:
    config:
      server:
        git:
          uri: https://github.com/huzhicheng/config-only-a-demo
          username: github 用户名
          password: github 密码
          default-label: master
          search-paths: config
```

```java
@SpringBootApplication
@EnableConfigServer
@EnableEurekaClient
public class Application {
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

##### Spring Cloud Config客户端

```xml
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-config</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

```yaml
## bootstrap.yml
eureka:
  client:
    serviceUrl:
      register-with-eureka: true
      fetch-registry: true
      defaultZone: http://test:123456@localhost:3000/eureka/
instance:
  preferIpAddress: true
spring:
  profiles:
    active: dev
---
spring:
  profiles: prod
  application:
    name: config-eureka-client
cloud:
    config:
      label: master
      profile: prod
      discovery:
        enabled: true
        service-id: config-eureka-server
---
spring:
  profiles: dev
  application:
    name: config-eureka-client  
  cloud:
    config:
      label: master  #指定仓库分支
      profile: dev   #指定版本 本例中建立了dev 和 prod两个版本
      discovery:
        enabled: true  # 开启
        service-id: config-eureka-server # 指定配置中心服务端的server-id
```

```yaml
## application.yml
server:
  port: 3011
management:
endpoint:
  shutdown:
    enabled: false
endpoints:
  web:
    exposure:
      include: "*"
data:
  env: NaN
  user:
    username: NaN
    password: NaN
```

```java
@SpringBootApplication
@EnableEurekaClient
public class Application {
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

#### 注意

1. 在 git 上的配置文件的名字要和 config 的 client 端的 application name 对应；
2. 在结合 eureka 的场景中，关于 eureka 和 git config 相关的配置要放在 bootstrap.yml 中，否则会请求默认的 config server 配置，这是因为当你加了配置中心，服务就要先去配置中心获取配置，而这个时候，application.yml 配置文件还没有开始加载，而 bootstrap.yml 是最先加载的。

### Spring Cloud Consul

Consul 提供的功能包括如下几个：

**服务发现**

Consul 让服务注册和服务发现（通过 DNS 和 HTTP 接口）更加简单，甚至对于外部服务（例如SaaS）注册也一样。

**故障检测**

通过健康检查，服务发现可以防止请求被路由到不健康的主机，并且可以使服务容易断开（不再提供服务）。

**多数据中心**

Consul 不需要复杂的配置即可简便的扩展到多个数据中心，查找其它数据中心的服务或者只请求当前数据中心的服务。

**键值存储**

灵活的键值存储，提供动态配置、特征标记、协作、leader 选举等功能，通过长轮询实现配置改变的即时通知。

Spring Cloud Consul 将 Consul 进行自动配置和进一步封装。

Spring Cloud Consul 可替代已有的 Spring Cloud Eureka，也就是当做服务注册发现框架使用。

Spring Cloud Consul 可替代已有的 Spring Cloud Config ，也就是当做配置中心使用。

| 功能点               | euerka                       | Consul                 | zookeeper             | etcd              |
| :------------------- | :--------------------------- | :--------------------- | :-------------------- | :---------------- |
| 服务健康检查         | 可配支持                     | 服务状态，内存，硬盘等 | (弱)长连接，keepalive | 连接心跳          |
| 多数据中心           | —                            | 支持                   | —                     | —                 |
| kv 存储服务          | —                            | 支持                   | 支持                  | 支持              |
| 一致性               | —                            | raft                   | paxos                 | raft              |
| cap                  | ap（高可用、分区容错）       | ca（数据一致、高可用） | cp                    | cp                |
| 使用接口(多语言能力) | http（sidecar）              | 支持 http 和 dns       | 客户端                | http/grpc         |
| watch 支持           | 支持 long polling/大部分增量 | 全量/支持long polling  | 支持                  | 支持 long polling |
| 自身监控             | metrics                      | metrics                | —                     | metrics           |
| 安全                 | —                            | acl /https             | acl                   | https 支持（弱）  |
| spring cloud 集成    | 已支持                       | 已支持                 | 已支持                | 已支持            |

Consul 采用 raft 算法来保证数据的强一致性，如此带来的优势很明显，相应的也带来了一些牺牲：

1. 服务注册相比 Eureka 会稍慢一些。因为 Consul 的 raft 协议要求必须过半数的节点都写入成功才认为注册成功；
2. Leader挂掉时，重新选举期间整个 consul 不可用，以此保证了强一致性但牺牲了可用性。

#### 服务提供者

```xml
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-consul-all</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<dependencyManagement>
   <dependencies>
       <dependency>
           <groupId>org.springframework.cloud</groupId>
           <artifactId>spring-cloud-consul-dependencies</artifactId>
           <version>2.1.0.M2</version>
           <type>pom</type>
           <scope>import</scope>
       </dependency>
   </dependencies>
</dependencyManagement>
```

```yaml
## bootstrap.yml
spring:
cloud:
  consul:
    discovery:
      service-name: consul-provider  # 服务提供者名称
    host: localhost                  # consul 所在服务地址
    port: 8500   # consul 端口
```

```yaml
## application.yml
spring:
application:
  name: consul-provider
server:
port: 5000
endpoints:
health:
  sensitive: false
restart:
  enabled: true
shutdown:
  enabled: true
management:
security:
  enabled: false
```

```java
@RestController
@Slf4j
public class HelloController {
   @Autowired
   private DiscoveryClient discoveryClient;
   @GetMapping(value = "test")
   public String test(){
       List<String> services = discoveryClient.getServices();
       for(String s : services){
           log.info(s);
      }
       return "hello spring cloud!";
  }
   @GetMapping(value = "nice")
   public String nice(){
       List<String> services = discoveryClient.getServices();
       for(String s : services){
           log.info("gogogo" + s);
      }
       return "nice to meet you!";
  }
}
```

```java
@SpringBootApplication
@EnableDiscoveryClient
public class Application {
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

#### 服务消费者

```xml
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```

```yaml
## bootstrap.yml
spring:
cloud:
  consul:
    discovery:
      register: false
```

```yaml
## application.yml
spring:
application:
  name: consul-customer
server:
port: 5001
endpoints:
health:
  sensitive: false
restart:
  enabled: true
shutdown:
  enabled: true
management:
security:
  enabled: false
```

```java
@SpringBootApplication
@EnableDiscoveryClient
@EnableFeignClients
public class Application {
   @Bean
   @LoadBalanced
   public RestTemplate restTemplate() {
       return new RestTemplate();
  }
   public static void main(String[] args) {
       SpringApplication.run(Application.class, args);
  }
}
```

```java
@FeignClient(value = "consul-provider")
public interface IHelloService {
   @RequestMapping(value = "/hello")
   String hello();
   @RequestMapping(value = "nice")
   String nice();
}
```

```java
@RestController
public class ConsumerController {
   @Autowired
   private LoadBalancerClient loadBalancer;
   @Autowired
   private DiscoveryClient discoveryClient;
   @Autowired
   private RestTemplate restTemplate;
   @Autowired
   private IHelloService helloService;
   private final static String SERVICE_NAME = "consul-provider";
   /**
    * 使用普通的 RestTemplate 方法访问服务
    *
    * @return
    */
   @GetMapping(value = "test")
   public Object test() {
       String result = restTemplate.getForObject("http://"+SERVICE_NAME + "/test", String.class);
       System.out.println(result);
       return result;
  }
   /**
    * 使用 openFeign 方式访问服务
    *
    * @return
    */
   @GetMapping(value = "feign")
   public Object feign() {
       String s = helloService.nice();
       return s;
  }
   
   /**
    * 获取所有服务实例
    *
    * @return
    */
   @GetMapping(value = "/services")
   public Object services() {
       return discoveryClient.getInstances(SERVICE_NAME);
  }
   /**
    * 从所有服务中选择一个服务（轮询）
    */
   @GetMapping(value = "/choose")
   public Object choose() {
       return loadBalancer.choose(SERVICE_NAME).getUri().toString();
  }
}
```

#### 实现高可用服务提供者

```yaml
## bootstrap.yml 
spring:
cloud:
  consul:
    discovery:
      service-name: consul-provider
    host: localhost
    port: 8500
```

```yaml
## application.yml
spring:
profiles:
  active: consul-provider1
endpoints:
health:
  sensitive: false
restart:
  enabled: true
shutdown:
  enabled: true
management:
security:
  enabled: false
---
spring:
profiles: consul-provider1
application:
  name: consul-provider1
server:
port: 5000
---
spring:
profiles: consul-provider2
application:
  name: consul-provider2
server:
port: 5002
```

#### 作配置中心

Spring Cloud Config 提供了配置中心的功能，但是需要配合 git、svn 或外部存储（例如各种数据库），那么既然使用了 Consul ，就可以使用 Consul 提供的配置中心功能，并且不需要额外的 git 、svn、数据库等配合使用。

```xml
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-consul-config</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

```yaml
## bootstrap.yml
spring:
cloud:
  consul:
    config:
      enabled: true    # 启用配置中心
      format: yaml     # 指定配置格式为 yaml
      data-key: mysql_config # 也就是 consul 中 key/value 中的 key
      prefix: config         # 可以理解为配置文件所在的最外层目录
      defaultContext: consul-config  # 可以理解为 mysql_config 的上级目录
    discovery:
      register: false
```

![图片](分布式/639.jpg)

```yaml
## application.yml
spring:
application:
  name: consul-config
server:
port: 5008
endpoints:
health:
  sensitive: false
restart:
  enabled: true
shutdown:
  enabled: true
management:
security:
  enabled: false
```

```java
@Component
@ConfigurationProperties(prefix = "mysql")
public class MySqlComplexConfig {
   public static class UserInfo{
       private String username;
       private String password;
       public String getUsername() {
           return username;
      }
       public void setUsername(String username) {
           this.username = username;
      }
       public String getPassword() {
           return password;
      }
       public void setPassword(String password) {
           this.password = password;
      }
       @Override
       public String toString() {
           return "UserInfo{" +
                   "username='" + username + '\'' +
                   ", password='" + password + '\'' +
                   '}';
      }
  }
   private String host;
   private UserInfo user;
   public String getHost() {
       return host;
  }
   public void setHost(String host) {
       this.host = host;
  }
   public UserInfo getUser() {
       return user;
  }
   public void setUser(UserInfo user) {
       this.user = user;
  }
}
```

```java
@RestController
@Slf4j
public class ConfigController {
   @Autowired
   private MySqlConfig mySqlConfig;
   @Autowired
   private MySqlComplexConfig mySqlComplexConfig;
   @GetMapping(value = "mysqlhost")
   public String getMysqlHost(){
       return mySqlConfig.getHost();
  }
   @GetMapping(value = "mysqluser")
   public String getMysqlUser(){
       log.info(mySqlComplexConfig.getHost());
       MySqlComplexConfig.UserInfo userInfo = mySqlComplexConfig.getUser();
       return userInfo.toString();
  }
}
```

### Spring Cloud Stream

Spring Cloud Stream 是消息中间件组件，它集成了 Kafka 和 RabbitMQ 。

#### 几个重要的概念

- Destination Binders：目标绑定器，目标指的是 kafka 还是 RabbitMQ，绑定器就是封装了目标中间件的包。如果操作的是 kafka 就使用 kafka binder ，如果操作的是 RabbitMQ 就使用 rabbitmq binder。
- Destination Bindings：外部消息传递系统和应用程序之间的桥梁，提供消息的“生产者”和“消费者”（由目标绑定器创建）
- Message：一种规范化的数据结构，生产者和消费者基于这个数据结构通过外部消息系统与目标绑定器和其他应用程序通信。

![图片](分布式/640.png)

#### 一个简单的例子

```xml
<dependency>
 <groupId>org.springframework.cloud</groupId>  
 <artifactId>spring-cloud-starter-stream-rabbit</artifactId>
</dependency>
```

```yaml
## application.yml
spring:
profiles: stream-rabbit-customer-group1
cloud:
  stream:
    bindings: # 可配置多个input或output，对应到rabbitmq上就是不同的exchange
      input:  # 接收通道
        destination: default.messages # exchange名称
        binder: local_rabbit
      output: # 发送通道
        destination: default.messages
        binder: local_rabbit
    binders:
      local_rabbit:
        type: rabbit # 如果用的是Kafka则设置为Kafka
        environment:
          spring:
            rabbitmq:
              host: localhost
              port: 32775
              username: guest
              password: guest
server:
port: 8201
```

另外还可以设置 group 。因为服务很可能不止一个实例，如果启动多个实例，那么没必要每个实例都消费同一个消息，只要把功能相同的实例的 group 设置为同一个，那么就会只有一个实例来消费消息，避免重复消费的情况。如果设置了 group，那么 group 名称就会成为 queue 的名称，如果没有设置 group ，那么 queue 就会根据 destination + 随机字符串的方式命名。

```java
import org.springframework.cloud.stream.annotation.Output;
import org.springframework.messaging.MessageChannel;
public interface Source {
   String OUTPUT = "output";
   @Output("output")
   MessageChannel output();
}
```

```java
import org.springframework.cloud.stream.annotation.Input;
import org.springframework.messaging.SubscribableChannel;
public interface Sink {
   String INPUT = "input";
   @Input("input")
   SubscribableChannel input();
}
```

```java
@SpringBootApplication
@EnableBinding(value = {Processor.class}) //启用 stream ，并指定定义的 Channel 定义接口类
@Slf4j
public class DefaultApplication {
   public static void main(String[] args) {
       SpringApplication.run(DefaultApplication.class, args);
  }
}
```

```java
@Slf4j
@Component
public class DefaultMessageListener {
   @StreamListener(Processor.INPUT) //表示对消息进行订阅监控，指定 binding 的名称，其中 Processor.INPUT 就是 Sink 的 input
   public void processMyMessage(String message) {
       log.info("接收到消息：" + message);
  }
}
```

#### 模拟日志处理

模拟生产者和消费者处理消息的过程，模拟一个日志处理的过程。

- 原始日志发送到 kite.log.messages exchange
- 接收器在 kite.log.messages exchange 接收原始日志，经过处理格式化，发送到 kite.log.format.messages exchange
- 接收器在 kite.log.format.messages exchange 接收格式化后的日志

**自定义消息通道接口**

```java
@Component
public interface MyProcessor {
   String MESSAGE_INPUT = "log_input";
   String MESSAGE_OUTPUT = "log_output";
   String LOG_FORMAT_INPUT = "log_format_input";
   String LOG_FORMAT_OUTPUT = "log_format_output";
   @Input(MESSAGE_INPUT)
   SubscribableChannel logInput();
   @Output(MESSAGE_OUTPUT)
   MessageChannel logOutput();
   @Input(LOG_FORMAT_INPUT)
   SubscribableChannel logFormatInput();
   @Output(LOG_FORMAT_OUTPUT)
   MessageChannel logFormatOutput();
}
```

**创建消费者应用**

```yaml
## application.yml
spring:
profiles: stream-rabbit-customer-group1
cloud:
  stream:
    bindings:
      log_input:
        destination: kite.log.messages
        binder: local_rabbit
        group: logConsumer-group1
      log_output:
        destination: kite.log.messages
        binder: local_rabbit
        group: logConsumer-group1
      log_format_input:
        destination: kite.log.format.messages
        binder: local_rabbit
        group: logFormat-group1
      log_format_input:
        destination: kite.log.format.messages
        binder: local_rabbit
        group: logFormat-group1
    binders:
      local_rabbit:
        type: rabbit
        environment:
          spring:
            rabbitmq:
              host: localhost
              port: 32775
              username: guest
              password: guest
server:
port: 8201
```

```java
@SpringBootApplication
@EnableBinding(value = {MyProcessor.class})
@Slf4j
public class CustomerApplication {
   public static void main(String[] args) {
       SpringApplication.run(CustomerApplication.class, args);
  }
}
```

```java
@Slf4j
@Component
public class LogMessageListener {
   /**
    * 通过 MyProcessor.MESSAGE_INPUT 接收消息
    * 然后通过 SendTo 将处理后的消息发送到 MyProcessor.LOG_FORMAT_OUTPUT
    * @param message
    * @return
    */
   @StreamListener(MyProcessor.MESSAGE_INPUT)
   @SendTo(MyProcessor.LOG_FORMAT_OUTPUT)
   public String processLogMessage(String message) {
       log.info("接收到原始消息：" + message);
       return "「" + message +"」";
  }
   /**
    * 接收来自 MyProcessor.LOG_FORMAT_INPUT 的消息
    * 也就是加工后的消息，也就是通过上面的 SendTo 发送来的
    * 因为 MyProcessor.LOG_FORMAT_OUTPUT 和 MyProcessor.LOG_FORMAT_INPUT 是指向同一 exchange
    * @param message
    */
   @StreamListener(MyProcessor.LOG_FORMAT_INPUT)
   public void processFormatLogMessage(String message) {
       log.info("接收到格式化后的消息：" + message);
  }
}
```

**创建一个消息生产者，用于发送原始日志消息**

```yaml
## application.yml
spring:
cloud:
  stream:
    bindings:
      log_output:
        destination: kite.log.messages
        binder: local_rabbit
        group: logConsumer-group1
    binders:
      local_rabbit:
        type: rabbit
        environment:
          spring:
            rabbitmq:
              host: localhost
              port: 32775
              username: guest
              password: guest
server:
port: 8202
```

仅仅指定了一个 binding log_output，用来发送消息，如果只做生产者就不要指定 log_input，如果指定了 log_input ，应用就会认为这个生产者服务也会消费消息，如果这时没有在此服务中订阅消息，当消息被发送到这个服务时，因为并没有订阅消息，也就是没有 @StreamListener 注解的方法，就会出现如下异常：

> org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel

```java
@Slf4j
@RestController
@EnableBinding(value = {MyProcessor.class})
public class MyMessageController {
   @Autowired
   private MyProcessor myProcessor;
   @GetMapping(value = "sendLogMessage")
   public void sendLogMessage(String message){
       Message<String> stringMessage = org.springframework.messaging.support.MessageBuilder.withPayload(message).build();
       myProcessor.logOutput().send(stringMessage);
  }
}
```

```java
@Slf4j
@RestController
@EnableBinding(value = {MyProcessor.class})
public class MyMessageController {
   @Autowired
   private MyProcessor myProcessor;
   @GetMapping(value = "sendLogMessage")
   public void sendLogMessage(String message){
       Message<String> stringMessage = org.springframework.messaging.support.MessageBuilder.withPayload(message).build();
       myProcessor.logOutput().send(stringMessage);
  }
}
```

#### 其他

消息除了可以是字符串类型，还可以是其他类型，也可以是实体类型，例如

```java
@GetMapping(value = "sendObjectLogMessage")
public void sendObjectLogMessage() {
   LogInfo logInfo = new LogInfo();
   logInfo.setClientIp("192.168.1.111");
   logInfo.setClientVersion("1.0");
   logInfo.setUserId("198663383837434");
   logInfo.setTime(Date.from(Instant.now()));
   Message < LogInfo > stringMessage = org.springframework.messaging.support.MessageBuilder.withPayload(logInfo).build();
   myProcessor.logOutput().send(stringMessage);
}
```

上面代码发送了一个 LogInfo 实体对象，在消费者端依然可以用字符串类型接收，因为 @StreamListener 注解会默认把实体转为 json 字符串。

另外，可以试着启动两个消费者端，把 group 设置成相同的，这时，发送的消息只会被一个消费者接收。

如果把 group 设置成不一样的，那么发送的消息会被两个消费者接收。

### Spring Cloud Gateway

网关可提供**请求路由与组合**、**协议转换**、**安全认证**、**服务鉴权**、**流量控制**与**日志监控**等服务。

#### 创建Spring Cloud Gateway项目

```java
@RestController
@RequestMapping(value = "order")
public class OrderController {
   @Value("${spring.application.name}")
   private String applicationName;
    
   //直接地址为 http://localhost:5006/order/get
   @GetMapping(value = "get")
   public CustomerOrder getOrder(){
       CustomerOrder customerOrder = new CustomerOrder();
       customerOrder.setOrderId("9999");
       customerOrder.setProductName("MacBook Pro");
       customerOrder.setClient(applicationName);
       return customerOrder;
  }
}
```

```java
@RestController
@RequestMapping(value = "user")
public class UserController {
   //直接地址为 http://localhost:5005/user-service/user/get
   @GetMapping(value = "get")
   public User getUserInfo(){
       User user = new User();
       user.setName("张三");
       user.setAge(8);
       user.setLocation("北京");
       return user;
  }
}
```

```yaml
server:
port: 5005
servlet:
  context-path: /user-service
```

```xml
<dependency>
   <groupId>org.springframework.cloud</groupId>
   <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-webflux</artifactId>
</dependency>
<dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

```yaml
server:
port: 10000
spring:
application:
  name: gateway
cloud:
  gateway:
    discovery:
      locator:
        enabled: true
        lower-case-service-id: false # 是否将服务id转换为小写
    routes:
    - id: userServiceRouter
      uri: lb://consul-user
      predicates:
      - Path=/user-service/**
    - id: orderServiceRouter
      uri: lb://consul-order
      predicates:
      - Path=/order-service/**
      filters:
      - StripPrefix=1 # 以 / 分隔，去掉第一部分 如 /a/b/c -> /b/c
  consul:
    host: localhost # 注册gateway网关到consul
    port: 8500
    discovery:
      service-name: service-gateway
```

```java
@Bean
public RouteLocator kiteRouteLocator(RouteLocatorBuilder builder) {
return builder.routes()
.route("userRouter", r -> r.path("/user-service/**")
.filters(f ->
f.addResponseHeader("X-CustomerHeader", "kite"))
.uri("lb://consul-user")
)
.route("orderRouter", r -> r.path("/order-service/**")
.filters(f -> f.stripPrefix(1)).uri("lb://consul-order")
)
.build();
}
```

#### 巧用StripPrefis filter

微服务多了之后，路由的转发规则也就多了，比方说订单相关请求要转发到订单微服务集群，用户相关请求要转发到用户微服务集群，最终开放给终端的接口也要能表明是哪个微服务的，除了接口文档里说明之外，接口本身最好也能明确标识。

一种方式是在微服务的配置文件中配置上server.servlet.context-path。

还有一种方式就是在路由规则的 path 中配置，然后加上 StripPrefix 配置，选择性的去掉请求 url 中的某些部分。比如我们请求 Gateway的地址为 order-service/order/get，则经过 StripPrefix(1) 之后，会把请求地址变为 order/get，然后根据路由规则定向到具体的微服务地址或者特定的 url。

### Zuul

Zuul底层利用各种filter实现如下功能：

- 认证和安全 识别每个需要认证的资源，拒绝不符合要求的请求。
- 性能监测 在服务边界追踪并统计数据，提供精确的生产视图。
- 动态路由 根据需要将请求动态路由到后端集群。
- 压力测试 逐渐增加对集群的流量以了解其性能。
- 负载卸载 预先为每种类型的请求分配容量，当请求超过容量时自动丢弃。
- 静态资源处理 直接在边界返回某些响应。

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-zuul</artifactId>
</dependency>
```

```yaml
server: 
	port: 9000 
eureka: 
	client: 
		serviceUrl: 
			defaultZone: http://localhost:8761/eureka/ 
spring: 
	application:
		name: api-gateway 
zuul: 
	routes: 
		orderService: /order/** 
		restaurantService: /restaurant/**
```

```java
@SpringBootApplication 
@EnableZuulProxy 
public class SpringcloudApigatewayApplication { 
    public static void main(String[] args){
        SpringApplication.run(SpringcloudApigatewayApplication.class, args); 
    } 
}
```

### Hystrix

```yaml
feign:
	hystrix: 
		enabled: true
```

```java
@FeignClient(name = "orderService", fallback = RestaurantFeignClientFallback.class)
//@FeignClient(name = "orderService")
public interface RestaurantFeignClient {
    @GetMapping("/api/v1/order/find")
    String findAllOrders(@RequestParam(value = "id") int id);
}
```

```java
@Component
public class RestaurantFeignClientFallback implements RestaurantFeignClient {

    @Override
    public String findAllOrders(int id) {
        System.out.println("降级处理！");
        return "{\"id\":\"0\",\"ordername\":\"default\"}";
    }
}
```

![image-20230430174405734](分布式/image-20230430174405734.png)

![image-20230430174420495](分布式/image-20230430174420495.png)

1. 构建一个HystrixCommand或者HystrixObservableCommand 对象。
   一个 HystrixCommand 或 HystrixObservableCommand 对象，代表了对某个依赖服务发 起的一次请求或者调用。 

2. 执行Command 
   execute()–阻塞，，然后返回从依赖关系接收到的单个响应（或者在发生错误时抛 出异常）
   queue()–返回一个可以从依赖关系获得单个响应的future 对象
   observe()–订阅Observable代表依赖关系的响应，并返回一个Observable，该 Observable会复制该来源Observable 
   toObservable()–返回一个Observable，当您订阅它时，将执行Hystrix命令并发出 其响应。

3. 响应是否有缓存？ 
   如果这个 command 开启了请求缓存 Request Cache，而且这个调用的结果在缓存中存 在，那么直接从缓存中返回结果。否则，继续往后的步骤。

4. 断路器是否打开？ 
   当您执行该命令时，Hystrix将检查断路器以查看电路是否打开。如果电路打开 （或“跳闸”），则Hystrix将不会执行该命令，但会将流程路由到（8）获取回退，而 是直接去执行 fallback 降级机制，返回降级结果。如果电路关闭，则流程进行到 （5）以检查是否有可用于运行命令的容量。

5. 线程池/队列/信号量是否已经满负载？
    如果与命令相关联的线程池和队列（或信号量，如果不在线程中运行）已满，则 Hystrix将不会执行该命令，但将立即将流程路由到（8）获取回退，直接去调用 fallback 降级机制，同时发送 reject 信息给断路器统计。

6. HystrixObservableCommand.construct() 或者 HystrixCommand.run() 

7. 计算Circuit 的健康Hystrix向断路器报告成功，失败，拒绝和超时，该断路器维护 了一系列的计算统计数据组。 如果打开了断路器，那么在接下来一段时间内，会直接断路，返回降级结果。 如果在之后，断路器尝试执行 command，调用没有出错，返回了正常结果，那么 Hystrix 就会把断路器关闭。

8. 获取Fallback 
   在以下几种情况中，Hystrix 会调用 fallback 降级机制。 

   1. 断路器处于打开状态； 

   2. 线程池/队列/semaphore满了；

   3. command 执行超时；

   4. run() 或者 construct() 抛出异常。 

   当命令执行失败时，Hystrix试图恢复到你的回退：当construct（）或run（）（6.） 抛出异常时，当命令由于电路断开而短路时（4.），当 命令的线程池和队列或信号量 处于容量（5.），或者当命令超过其超时长度时。 
      编写Fallback ,它不一依赖于任何的网络依赖，从内存中获取获取通过其他的静态逻 辑。如果你非要通过网络去获取Fallback,你可能需要些在获取服务的接口的逻辑上写 一个HystrixCommand。

9. 返回成功的响应如果 Hystrix command成功，如果Hystrix命令成功，它将以 Observable的形式返回对呼叫者的响应或响应。

## Spring Cloud Alibaba

### Nacos

Nacos：Dynamic Naming and Configuration Service，注册中心 + 配置中心的组合。

- 替代Eureka做服务注册中心。
- 替代Config做服务配置中心。

#### 简单实例

**父工程pom文件**

```xml
<dependencyManagement>
    <dependencies>
        <!--spring cloud alibaba-->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-alibaba-dependencies</artifactId>
            <version>2.1.0.RELEASE</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
        <!--spring cloud Hoxton.SR1-->
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-dependencies</artifactId>
            <version>Hoxton.SR1</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
        <!--spring boot 2.2.2-->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-dependencies</artifactId>
            <version>2.2.2.RELEASE</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

**服务提供者**

```xml
<dependencies>
    <!--spring cloud alibaba nacos-->
    <dependency>
        <groupId>com.alibaba.cloud</groupId>
        <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
    </dependency>
    <!--web-->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <!--actuator-->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
</dependencies>
```

```yml
server:
  port: 9001
spring:
  application:
    name: nacos-payment-provider
  cloud:
    # nacos地址和端口的配置 
    nacos:
      discovery:
        server-addr: Nacos服务器地址:8848
management:
  endpoints:
    web:
      exposure:
        include: '*'
```

```java
package com.ymy.spring.cloud.alibaba;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

@SpringBootApplication
@EnableDiscoveryClient // 开启服务的发现
public class PaymentMain9001 {
    public static void main(String[] args) {
        SpringApplication.run(PaymentMain9001.class, args);
    }
}
```

```java
package com.ymy.spring.cloud.alibaba.controller;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class PaymentController {
    
    // 获取配置文件中服务的端口
    @Value("${server.port}")
    private String serverPort;

    @GetMapping("/payment/nacos/port")
    public String getServerPort() {
        return "server port----> " + serverPort;
    }
}
```

**服务消费者**

```xml
<dependencies>
    <!--spring cloud alibaba nacos-->
    <dependency>
        <groupId>com.alibaba.cloud</groupId>
        <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
    </dependency>
    <!--web-->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <!--actuator-->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
</dependencies>
```

```yaml
server:
  port: 83
spring:
  application:
    name: nacos-order-consumer
  cloud:
    nacos:
      discovery:
        server-addr: Nacos服务器地址:8848

# 消费者将要去访问的微服务名称(注册成功进Nacos的微服务提供者) 这个属性是自己写的 不是Spring提供的
service-url:
  nacos-user-service: http://nacos-payment-provider
```

```java
package com.ymy.spring.cloud.alibaba;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

@SpringBootApplication
@EnableDiscoveryClient // 开启服务的发现
public class ConsumerMain83 {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerMain83.class, args);
    }
}
```

```java
package com.ymy.spring.cloud.alibaba.conf;

import org.springframework.cloud.client.loadbalancer.LoadBalanced;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.client.RestTemplate;

@Configuration
public class MainConf {

    /**
     * 将RestTemplate加入到Spring容器
     * 开启负载均衡
     */
    @Bean
    @LoadBalanced // 一定不要忘记@LoadBalanced开启负载均衡
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }
}
```

```java
package com.ymy.spring.cloud.alibaba.controller;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import javax.annotation.Resource;

@RestController
public class ConsumerController {

    @Resource
    private RestTemplate restTemplate;

    // 从配置文件中读取到Provider的微服务名称
    @Value("${service-url.nacos-user-service}") 
    private String serverURL;

    @GetMapping("/consumer")
    public String paymentInfo() {
        return restTemplate.getForObject(serverURL + "/payment/nacos/port", String.class);
    }
}
```

#### Nacos服务注册中心对比

Nacos支持AP和CP模式的切换。

- **C是所有节点在同一时间看到的数据是一致的；而A的定义是所有的请求都会收到响应。**

- 一般来说，如果不需要存储服务级别的信息且服务实例是通过nacos-client注册，并且能够保证心跳上限，那么就可以选择AP模式。当前主流的服务如Spring Cloud和Dubbo服务，都适用于AP模式，AP模式为了服务的可用性而减弱了一致性，因此AP模式下只支持注册临时实例。

- 如果需要在服务级别编辑或者存储配置信息，那么CP是必须的，K8S服务和DNS服务则适用于CP模式。CP模式下则支持注册持久化实例，此时则是以Raft协议为集群运行模式，该模式下注册实例前必须先注册服务，如果服务不存在，则会返回错误。

- **Nacos默认是AP模式，切换CP命令如下：**

  ```shell
  curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&value=CP'
  ```


#### Nacos服务配置中心

##### 基础配置

 ```xml
 <dependencies>
     <!--spring cloud alibaba nacos config 和配置中心相关-->
     <dependency>
         <groupId>com.alibaba.cloud</groupId>
         <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
     </dependency>
     <!--spring cloud alibaba nacos discovery 和服务注册相关-->
     <dependency>
         <groupId>com.alibaba.cloud</groupId>
         <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
     </dependency>
     <!--web-->
     <dependency>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-web</artifactId>
     </dependency>
     <!--actuator-->
     <dependency>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-actuator</artifactId>
     </dependency>
 </dependencies>
 ```

```yaml
# 1、为什么要写两个配置文件？？
#   Nacos和SpringCloudConfig一样，在项目初始化时，要保证先从配置中心进行拉取配置，配置拉取成功之后，才能保证项目的正常启动。

# 2、SpringBoot中配置文件的加载顺序是存在优先级的，bootstrap.yml优先级高于application.yml

# 3、 Nacos dataID格式：${prefix}-${spring.profile.active}.${file-extension}
#  · prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。
#  · spring.profile.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。 注意：当 spring.profile.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 ${prefix}.${file-extension}
#  · file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。

# 4、Nacos服务器上配置文件的DataID：global-service-config-dev.yaml

server:
  port: 3377
spring:
  application:
    name: nacos-config-client
  cloud:
    nacos:
      discovery:
        server-addr: 39.97.3.60:8848 # Nacos服务注册中心地址
      config:
        server-addr: 39.97.3.60:8848 # Nacos 服务配置中心地址
        file-extension: yaml # 指定配置文件的类型是yaml
        prefix: global-service-config
```

```yaml
spring:
  profiles:
    active: dev # 代表开发环境
```

```java
package com.ymy.spring.cloud.alibaba;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

@SpringBootApplication
@EnableDiscoveryClient // 开启服务发现
public class ConfigClientMain3377 {
    public static void main(String[] args) {
        SpringApplication.run(ConfigClientMain3377.class, args);
    }
}
```

```java
package com.ymy.spring.cloud.alibaba.controller;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.cloud.context.config.annotation.RefreshScope;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RefreshScope   // @RefreshScope 支持Nacos的动态刷新功能
public class ConfigClientController {
    @Value("${config.info}")
    private String configInfo;

    @GetMapping("/config/info")
    public String getConfigInfo() {
        return configInfo;
    }
}
```

##### 分类配置

1. Namespcae + Group + DataID 是什么？

   类似Java中的Package名和类名，最外层的Namespace是可以用于区分部署环境的，Group和DataID逻辑上区分两个目标对象。

2. 三者情况 默认：Namespace=public，Group=DEFAULT_GROUP，Cluster是DEFAULT。

   Nacos默认的命名空间是public，Namespace主要用来实现隔离。
   比如说我们现在有三个环境：开发、测试、生产环境，我们就可以创建3个Namespace，不同的Namespace之间是隔离的。

   Group默认是DEFAULT_GROUP，Group可以把不同的微服务划分到同一个分组中去。

   Service就是微服务，一个Service可以包含多个Cluster(集群)，Nacos默认Cluster是DEFAULT，Cluster是对指定微服务的一个虚拟划分。比如为了容灾，将Service微服务分别部署在杭州机房和广州机房，这时就可以给杭州机房的Service微服务起一个集群名称(HZ)，给广州机房的Service微服务起一个集群名称(GZ)，还可以尽量让一个机房的微服务相互调用，来提升性能。

#### Nacos集群和持久化配置

##### Nacos部署说明

1. Nacos存储简介

   默认Nacos使用嵌入式数据库来实现数据的存储。所以，如果启动多个默认配置下的Nacos节点，数据存储一致性是存在问题的。
   为了解决这个问题，**Nacos采用了集中式存储的方式支持集群化部署**，目前只支持MySQL存储。

2. Nacos支持三种部署模式

   单机模式-用于测试和单机使用。
   集群模式-用于生产环境，确保高可用性。
   多集群模式-用于多数据中心场景。

##### Nacos持久化切换配置

```properties
# 官网：https://nacos.io/zh-cn/docs/deployment.html
# Nacos默认自带的是嵌入式数据库Derby。
# Derby到mysql切换步骤配置：（mysql version 5.6.5+）
# 1、再 nacos/conf/ 目录下找到sql脚本 nacos-mysql.sql。
# 2、创建数据库，数据库名字为 nacos_config。
# 3、在 nacos_config 数据库中执行sql脚本到数据库创建表。
# 4、修改conf/application.properties文件，增加支持mysql数据源配置（目前只支持mysql），添加mysql数据源的url、用户名和密码。
spring.datasource.platform=mysql

db.num=1
db.url.0=jdbc:mysql://39.97.3.60:3306/nacos_config?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true
db.user=root
db.password=333

# 5、再以单机模式启动nacos，nacos所有写嵌入式数据库的数据都写到了mysql
```

### Sentinel

#### Sentinel简介

随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。

- **丰富的应用场景**：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。
- **完备的实时监控**：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。
- **广泛的开源生态**：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。
- **完善的 SPI 扩展点**：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。

#### Sentinel初始化监控

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>spring-cloud-alibaba</artifactId>
        <groupId>com.ymy</groupId>
        <version>1.0-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>spring-cloud-alibaba-sentinel-service-8401</artifactId>

    <dependencies>
        <!--spring cloud alibaba sentinel 和服务熔断相关-->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
        </dependency>

        <!--spring cloud alibaba nacos discovery 和服务注册相关-->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
        </dependency>

        <!--持久化会用到-->
        <dependency>
            <groupId>com.alibaba.csp</groupId>
            <artifactId>sentinel-datasource-nacos</artifactId>
        </dependency>

        <!--web-->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <!--actuator-->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>
    </dependencies>

</project>
```

```yaml
server:
  port: 8401
spring:
  application:
    name: cloud-alibaba-sentinel-service
  cloud:
    nacos:
      discovery:
        server-addr: 39.97.3.60:1111 # Nginx地址反向代理到Nacos集群
    sentinel:
      transport:
        dashboard: localhost:8080 # 配置Sentinel Dashboard浏览器控制台地址 8080会监控8401服务
        port: 8719 # Sentinel默认端口8719
management:
  endpoints:
    web:
      exposure:
        include: '*'
```

```java
package com.ymy.spring.cloud.alibaba;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

@SpringBootApplication
@EnableDiscoveryClient // 开启服务的发现
public class SentinelMain8401 {
    public static void main(String[] args) {
        SpringApplication.run(SentinelMain8401.class, args);
    }
}
```

```java
package com.ymy.spring.cloud.alibaba.controller;

import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class FlowLimitController {

    @GetMapping("/testA")
    public String testA() {
        return "*********test A*********";
    }

    @GetMapping("/testB")
    public String testB() {
        return "*********test B*********";
    }
}
```

#### Sentinel流量控制规则

##### 流控规则基本介绍

- 资源名：唯一名称，默认请求路径。
- 针对来源：Sentinel可以针对调用者进行限流，填写微服务名，默认default（不区分来源）。
- 阈值类型/单机阈值：
  - **QPS（每秒钟的请求数量）：当调用该api的QPS达到阈值的时候，进行限流。**
  - **线程数：当调用该api的线程数达到阈值的时候，进行限流。**
- 是否集群：不需要集群。
- 流控模式：
  - 直接：api达到限流条件时，直接限流。
  - 关联：当关联的资源达到阈值时，就限流自己。
  - 链路：只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流）【api级别的针对来源】。
- 流控效果：
  - 快速失败：直接失败，抛异常。
  - Warm Up：根据coldFactor（冷加载因子，默认3）的值，从阈值/coldFactor，经过预热时长，才达到设置的QPS阈值。
  - 排队等待：匀速排队，让请求以均匀的速度通过，阈值类型必须为QPS，否则无效。

##### 流控模式

1. 直接：快速失败 系统默认的
2. 关联：当关联的资源达到阈值时，就限流自己；当与A关联的资源B达到阈值后，就限流A自己
3. 链路：链路的控制指的就是对一条链路的访问进行控制

##### 流控效果

1. warm up预热：默认coldFactor为3，即请求QPS从(阈值/3)开始，经过多少【预热时长】才逐渐升至设定的QPS阈值。
2. 排队等待：匀速排队，让请求以均匀的速度通过，阈值类型必须为QPS，否则无效。

#### Sentinel服务降级

##### 降级策略基本介绍

- 平均响应时间 (DEGRADE_GRADE_RT)：当 1s 内持续进入 N 个请求，对应时刻的平均响应时间（秒级）均超过阈值（count，以 ms 为单位），那么在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地熔断（抛出 DegradeException）。注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。
- 异常比例 (DEGRADE_GRADE_EXCEPTION_RATIO)：当资源的每秒请求量 >= N（可配置），并且每秒异常总数占通过量的比值超过阈值（DegradeRule 中的 count）之后，资源进入降级状态，即在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。
- 异常数 (DEGRADE_GRADE_EXCEPTION_COUNT)：当资源近 1 分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60s，则结束熔断状态后仍可能再进入熔断状态。

##### 对服务降级的进一步说明

- Sentinel熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），対这个资源的调用进行限制，让请求快速失败，避免影响到其他的资源而导致级联错误。
- 当资源被降级后，在接下来的【降级时间窗】内，対该资源的调用都是自动熔断（默认行为是抛出DegradeException）。
- Sentinel的断路器是没有半开的状态的，只有以下两种情况：
  - 保险丝合上，可以通过。
  - 保险丝关闭，不能通过。

##### 服务降级策略

- RT：平均响应时间，1秒持续进入5个请求 ---> 触发降级(断路器打开) ---> 时间窗口结束 ---> 关闭降级
- 异常比例：QPS >= 5 && 异常比例(秒级统计)超过阈值 ---> 触发降级(断路器打开) ---> 时间窗口结束 ---> 关闭降级
- 异常数：异常数(分钟统计)超过阈值 ---> 触发降级(断路器打开) ---> 时间窗口结束 ---> 关闭降级

#### 系统自适应限流

##### 系统规则的基本介绍

系统保护规则是从应用级别的入口流量进行控制，从单台机器的 load、CPU 使用率、平均 RT、入口 QPS 和并发线程数等几个维度监控应用指标，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。

系统保护规则是应用整体维度的，而不是资源维度的，并且仅对入口流量生效。入口流量指的是进入应用的流量（EntryType.IN），比如 Web 服务或 Dubbo 服务端接收的请求，都属于入口流量。

- Load 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。
- CPU usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。
- 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。
- 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。
- 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。

#### @SentinelResource注解

##### 按资源名称进行限流

```java
@GetMapping("/byResource")
@SentinelResource(value = "byResource", blockHandler = "byResourceHandler")
public SimpleResponse byResource() {
    return new SimpleResponse(200, "按资源名称限流OK！", new Payment("1", "serial01"));
}

/**
* 这个就是兜底方法,自定义的限流友好提示
*/
public SimpleResponse byResourceHandler(BlockException e) {
    return new SimpleResponse(444, e.getClass().getName() + "\t 服务不可用！");
}
```

资源名： byResource

阈值类型： QPS

单机阈值： 1

##### 按URL地址进行限流

```java
/**
* 没有兜底方法 将采用系统默认的
*/
@GetMapping("/rateLimit/byUrl")
@SentinelResource(value = "byUrl")
public SimpleResponse byUrl() {
    return new SimpleResponse(200, "按url限流OK！", new Payment("2", "serial02"));
}
```

资源名： /rateLimit/byUrl

阈值类型： QPS

单机阈值： 1

**上面两种兜底方案面临的问题**

- 系统默认的，没有体现出我们自己的业务要求。
- 依照现有条件，我们自定义的处理方法又和业务代码耦合在一起不直观。
- 每个业务方法都添加一个兜底的，那代码膨胀加剧。
- 全局统一的处理方法没有体现。

##### 自定义限流处理逻辑

```java
package com.ymy.spring.cloud.alibaba.handler;

import com.alibaba.csp.sentinel.slots.block.BlockException;
import com.ymy.spring.cloud.entity.SimpleResponse;

public class CustomerBlockHandler {
    /**
     * 全局兜底方案
     * 这里一定要static
     */
    public static SimpleResponse handlerException(BlockException e) {
        return new SimpleResponse(444, "按用户自定义,全局兜底方案");
    }
}
```

```java
/**
* 用户自定义限流处理逻辑
* 限流的时候会去全局兜底的类找指定的方法
*/
@GetMapping("/rateLimit/customerBlockHandler")
@SentinelResource(value = "customerBlockHandler",
                  blockHandlerClass = CustomerBlockHandler.class,
                  blockHandler = "handlerException")
public SimpleResponse customerBlockHandler() {
    return new SimpleResponse(200, "按用户自定义限流OK！", new Payment("3", "serial03"));
}
```

##### @SentinelSource注解属性说明

`@SentinelResource` 用于定义资源，并提供可选的异常处理和 fallback 配置项。 `@SentinelResource` 注解包含以下属性：

- `value`：资源名称，必需项（不能为空）。

- `entryType`：entry 类型，可选项（默认为 `EntryType.OUT`）。

- `blockHandler` / `blockHandlerClass`: `blockHandler` 对应处理 `BlockException` 的函数名称，可选项。blockHandler 函数访问范围需要是 `public`，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 `BlockException`。blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 `blockHandlerClass` 为对应的类的 `Class` 对象，注意对应的函数必需为 static 函数，否则无法解析。

- ```
  fallback
  ```

  /

  ```
  fallbackClass
  ```

  ：fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了

  ```
  exceptionsToIgnore
  ```

  里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求：

  - 返回值类型必须与原函数返回值类型一致；
  - 方法参数列表需要和原函数一致，或者可以额外多一个 `Throwable` 类型的参数用于接收对应的异常。
  - fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 `fallbackClass` 为对应的类的 `Class` 对象，注意对应的函数必需为 static 函数，否则无法解析。

- ```
  defaultFallback
  ```

  （since 1.6.0）：默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了

  ```
  exceptionsToIgnore
  ```

  里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。defaultFallback 函数签名要求：

  - 返回值类型必须与原函数返回值类型一致；
  - 方法参数列表需要为空，或者可以额外多一个 `Throwable` 类型的参数用于接收对应的异常。
  - defaultFallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 `fallbackClass` 为对应的类的 `Class` 对象，注意对应的函数必需为 static 函数，否则无法解析。

- `exceptionsToIgnore`（since 1.6.0）：用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 fallback 逻辑中，而是会原样抛出。

#### Sentinel服务熔断

```xml
<!--open feign-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```

```yaml
# 激活Sentinel対Feign的支持
feign:
  sentinel:
    enabled: true
```

```java
package com.ymy.spring.cloud.alibaba;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
import org.springframework.cloud.openfeign.EnableFeignClients;

@SpringBootApplication
@EnableDiscoveryClient
@EnableFeignClients
public class ConsumerMain84 {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerMain84.class, args);
    }
}
```

```java
package com.ymy.spring.cloud.alibaba.service;

import com.ymy.spring.cloud.alibaba.service.impl.FeignServiceFallback;
import com.ymy.spring.cloud.entity.Payment;
import com.ymy.spring.cloud.entity.SimpleResponse;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;

@FeignClient(value = "cloud-alibaba-provider", fallback = FeignServiceFallback.class)
public interface FeignService {

    // 直接复制Provider的方法即可
    @GetMapping("/payment/{id}")
    public SimpleResponse<Payment> payment(@PathVariable("id") String id);
}
```

```java
package com.ymy.spring.cloud.alibaba.service.impl;

import com.ymy.spring.cloud.alibaba.service.FeignService;
import com.ymy.spring.cloud.entity.SimpleResponse;
import org.springframework.stereotype.Component;

@Component
public class FeignServiceFallback implements FeignService {
    @Override
    public SimpleResponse payment(String id) {
        return new SimpleResponse(444444, "openFeign fallback");
    }
}
```

```java
package com.ymy.spring.cloud.alibaba.controller;

import com.ymy.spring.cloud.alibaba.service.FeignService;
import com.ymy.spring.cloud.entity.Payment;
import com.ymy.spring.cloud.entity.SimpleResponse;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RestController;

import javax.annotation.Resource;

@RestController
public class OpenFeignController {

    @Resource
    private FeignService feignService;

    @GetMapping("/openFeign/consumer/{id}")
    public SimpleResponse<Payment> consumer(@PathVariable("id") String id) {
        SimpleResponse<Payment> ret = feignService.payment(id);
        return ret;
    }
}
```

#### Sentinel持久化

```xml
<!--sentinel持久化相关-->
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-datasource-nacos</artifactId>
</dependency>
```

```yaml
server:
  port: 8401
spring:
  application:
    name: cloud-alibaba-sentinel-service
  cloud:
    nacos:
      discovery:
        server-addr: 39.97.3.60:1111 # Nginx地址反向代理到Nacos集群
    sentinel:
      transport:
        dashboard: localhost:8080 # 配置Sentinel Dashboard浏览器控制台地址 8080会监控8401服务
        port: 8719 # Sentinel默认端口8719
      # Sentinel持久化配置
      datasource:
        ds1:
          nacos:
            server-addr: 39.97.3.60:1111
            data-id: ${spring.application.name}
            group-id: DEFAULT_GROUP # 默认设置好了这里可以不写
            data-type: json # 默认设置好了这里可以不写
            rule-type: flow
management:
  endpoints:
    web:
      exposure:
        include: '*'
```

```json
// Nacos的配置
[
    {
        "resource": "/rateLimit/byUrl",
        "limitApp": "default",  
        "grade": 1,
        "count": 1,
        "strategy": 0,
        "controlBehavior": 0,
        "clusterMode": false
    }
]
```

## Dubbo

### Dubbo角色

| 节点      | 角色说明                               |
| --------- | -------------------------------------- |
| Provider  | 暴露服务的服务提供方                   |
| Consumer  | 调用远程服务的服务消费方               |
| Registry  | 服务注册与发现的注册中心               |
| Monitor   | 统计服务的调用次数和调用时间的监控中心 |
| Container | 服务运行容器                           |

![摘自官网](分布式/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy81ODI0MDE2LWU1OTliNDA0NjZlODRjNmIuanBn.jpeg)

发布-订阅：

- 启动容器，加载，**运行服务提供者**。
- 服务提供者在启动时，在注册中心**发布注册**自己提供的**服务**。
- 服务消费者在启动时，在注册中心**订阅**自己所需的**服务**。

考虑**失败或变更**的情况，就需要考虑下面的过程：

- 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
- 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
- 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。

### 入门实战（xml配置方式）

#### 服务端

```java
/**
 * xml方式服务提供者接口
 */
public interface ProviderService {

    String SayHello(String word);
}
```

```java
/**
 * xml方式服务提供者实现类
 */
public class ProviderServiceImpl implements ProviderService{

    public String SayHello(String word) {
        return word;
    }
}
```

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.ouyangsihai</groupId>
    <artifactId>dubbo-provider</artifactId>
    <version>1.0-SNAPSHOT</version>

    <dependencies>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>3.8.1</version>
            <scope>test</scope>
        </dependency>
        <!-- https://mvnrepository.com/artifact/com.alibaba/dubbo -->
        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>dubbo</artifactId>
            <version>2.6.6</version>
        </dependency>
        <dependency>
            <groupId>org.apache.zookeeper</groupId>
            <artifactId>zookeeper</artifactId>
            <version>3.4.10</version>
        </dependency>
        <dependency>
            <groupId>com.101tec</groupId>
            <artifactId>zkclient</artifactId>
            <version>0.5</version>
        </dependency>
        <dependency>
            <groupId>io.netty</groupId>
            <artifactId>netty-all</artifactId>
            <version>4.1.32.Final</version>
        </dependency>
        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-framework</artifactId>
            <version>2.8.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-recipes</artifactId>
            <version>2.8.0</version>
        </dependency>

    </dependencies>
</project>
```

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"
       xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">
	<!--provider.xml-->
    <!--配置name作整个项目在分布式架构中的唯一名称，配置owner表示属于谁-->
    <dubbo:application name="provider" owner="sihai">
        <dubbo:parameter key="qos.enable" value="true"/>
        <dubbo:parameter key="qos.accept.foreign.ip" value="false"/>
        <dubbo:parameter key="qos.port" value="55555"/>
    </dubbo:application>
	<!--监控中心配置， 用于配置连接监控中心相关信息，可以不配置，不是必须的参数-->
    <dubbo:monitor protocol="registry"/>

    <!--dubbo这个服务所要暴露的服务地址所对应的注册中心-->
    <!--N/A表示由dubbo自动分配地址，或者说是一种直连的方式，不通过注册中心-->
    <dubbo:registry address="N/A" />

    <!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http-->
    <dubbo:protocol name="dubbo" port="20880"/>

    <!--服务发布的配置，需要暴露的服务接口-->
    <dubbo:service
            interface="com.sihai.dubbo.provider.service.ProviderService"
            ref="providerService"/>

    <!--Bean bean定义-->
    <bean id="providerService" class="com.sihai.dubbo.provider.service.ProviderServiceImpl"/>

</beans>
```

```java
package com.sihai.dubbo.provider;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ProtocolConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.alibaba.dubbo.config.ServiceConfig;
import com.alibaba.dubbo.container.Main;
import com.sihai.dubbo.provider.service.ProviderService;
import com.sihai.dubbo.provider.service.ProviderServiceImpl;
import org.springframework.context.support.ClassPathXmlApplicationContext;

import java.io.IOException;

/**
 * xml方式启动
 *
 */
public class App 
{
    public static void main( String[] args ) throws IOException {
        //加载xml配置文件启动
        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("META-INF/spring/provider.xml");
        context.start();
        System.in.read(); // 按任意键退出
    }
}
```

**dubbo暴露的url**

> dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService?anyhost=true&application=provider&bean.name=com.sihai.dubbo.provider.service.ProviderService&bind.ip=192.168.234.1&bind.port=20880&dubbo=2.0.2&generic=false&interface=com.sihai.dubbo.provider.service.ProviderService&methods=SayHello&owner=sihai&pid=8412&qos.accept.foreign.ip=false&qos.enable=true&qos.port=55555&side=provider&timestamp=1562077289380

? 之前的链接，构成：协议://ip:端口/接口。

? 之后的字符串是在 provider.xml 中配置的字段，然后通过 & 拼接。

#### 消费端

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"
       xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">
	<!--consumer.xml-->
    <!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签-->
    <dubbo:application name="consumer" owner="sihai"/>

    <!--dubbo这个服务所要暴露的服务地址所对应的注册中心-->
    <!--点对点的方式-->
    <dubbo:registry address="N/A" />
    <!--<dubbo:registry address="zookeeper://localhost:2181" check="false"/>-->

    <!--生成一个远程服务的调用代理-->
    <!--点对点方式-->
    <dubbo:reference id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"
                     url="dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService"/>

    <!--<dubbo:reference id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"/>-->

</beans>
```

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.ouyangsihai</groupId>
    <artifactId>dubbo-consumer</artifactId>
    <version>1.0-SNAPSHOT</version>

    <dependencies>
        <dependency>
            <groupId>com.ouyangsihai</groupId>
            <artifactId>dubbo-provider</artifactId>
            <version>1.0-SNAPSHOT</version>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>3.8.1</version>
            <scope>test</scope>
        </dependency>
        <!-- https://mvnrepository.com/artifact/com.alibaba/dubbo -->
        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>dubbo</artifactId>
            <version>2.6.6</version>
        </dependency>
        <dependency>
            <groupId>org.apache.zookeeper</groupId>
            <artifactId>zookeeper</artifactId>
            <version>3.4.10</version>
        </dependency>
        <dependency>
            <groupId>com.101tec</groupId>
            <artifactId>zkclient</artifactId>
            <version>0.5</version>
        </dependency>
        <dependency>
            <groupId>io.netty</groupId>
            <artifactId>netty-all</artifactId>
            <version>4.1.32.Final</version>
        </dependency>
        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-framework</artifactId>
            <version>2.8.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-recipes</artifactId>
            <version>2.8.0</version>
        </dependency>
    </dependencies>
</project>
```

```java
package com.sihai.dubbo.consumer;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ReferenceConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.sihai.dubbo.provider.service.ProviderService;
import org.springframework.context.support.ClassPathXmlApplicationContext;

import java.io.IOException;

/**
 * xml的方式调用
 *
 */
public class App 
{
    public static void main( String[] args ) throws IOException {

        ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext("consumer.xml");
        context.start();
        ProviderService providerService = (ProviderService) context.getBean("providerService");
        String str = providerService.SayHello("hello");
        System.out.println(str);
        System.in.read();

    }
}
```

### zookeeper注册中心加入dubbo

#### 服务端

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"
       xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">

    <!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签-->
    <dubbo:application name="provider" owner="sihai">
        <dubbo:parameter key="qos.enable" value="true"/>
        <dubbo:parameter key="qos.accept.foreign.ip" value="false"/>
        <dubbo:parameter key="qos.port" value="55555"/>
    </dubbo:application>

    <dubbo:monitor protocol="registry"/>

    <!--dubbo这个服务所要暴露的服务地址所对应的注册中心-->
    <!--<dubbo:registry address="N/A"/>-->
    <dubbo:registry address="zookeeper://localhost:2181" check="false"/>
    <!--zookeeper集群-->
    <!--<dubbo:registry protocol="zookeeper" address="192.168.11.129:2181,192.168.11.137:2181,192.168.11.138:2181"/>-->

    <!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http-->
    <dubbo:protocol name="dubbo" port="20880"/>

    <!--服务发布的配置，需要暴露的服务接口-->
    <dubbo:service
            interface="com.sihai.dubbo.provider.service.ProviderService"
            ref="providerService"/>

    <!--Bean bean定义-->
    <bean id="providerService" class="com.sihai.dubbo.provider.service.ProviderServiceImpl"/>

</beans>
```

#### 消费端

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"
       xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">

    <!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签-->
    <dubbo:application name="consumer" owner="sihai"/>

    <!--dubbo这个服务所要暴露的服务地址所对应的注册中心-->
    <!--点对点的方式-->
    <!--<dubbo:registry address="N/A" />-->
    <dubbo:registry address="zookeeper://localhost:2181" check="false"/>

    <!--生成一个远程服务的调用代理-->
    <!--点对点方式-->
    <!--<dubbo:reference id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"
                     url="dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService"/>-->

    <dubbo:reference id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"/>

</beans>
```

### dubbo多种配置方式

#### API配置方式

```java
package com.sihai.dubbo.provider;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ProtocolConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.alibaba.dubbo.config.ServiceConfig;
import com.sihai.dubbo.provider.service.ProviderService;
import com.sihai.dubbo.provider.service.ProviderServiceImpl;

import java.io.IOException;

/**
 * Api方式启动
 * api的方式调用不需要其他的配置，只需要下面的代码即可。
 * 但是需要注意，官方建议：
 * Api方式用于测试用例使用，推荐xml的方式
 */
public class AppApi
{
    public static void main( String[] args ) throws IOException {

        // 服务实现
        ProviderService providerService = new ProviderServiceImpl();

        // 当前应用配置
        ApplicationConfig application = new ApplicationConfig();
        application.setName("provider");
        application.setOwner("sihai");

        // 连接注册中心配置
        RegistryConfig registry = new RegistryConfig();
        registry.setAddress("zookeeper://localhost:2181");
//        registry.setUsername("aaa");
//        registry.setPassword("bbb");

        // 服务提供者协议配置
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setName("dubbo");
        protocol.setPort(20880);
        //protocol.setThreads(200);

        // 注意：ServiceConfig为重对象，内部封装了与注册中心的连接，以及开启服务端口

        // 服务提供者暴露服务配置
        ServiceConfig<ProviderService> service = new ServiceConfig<ProviderService>(); // 此实例很重，封装了与注册中心的连接，请自行缓存，否则可能造成内存和连接泄漏
        service.setApplication(application);
        service.setRegistry(registry); // 多个注册中心可以用setRegistries()
        service.setProtocol(protocol); // 多个协议可以用setProtocols()
        service.setInterface(ProviderService.class);
        service.setRef(providerService);
        service.setVersion("1.0.0");

        // 暴露及注册服务
        service.export();
    }
}

```

> org.apache.dubbo.config.ServiceConfig
> org.apache.dubbo.config.ReferenceConfig
> org.apache.dubbo.config.ProtocolConfig
> org.apache.dubbo.config.RegistryConfig
> org.apache.dubbo.config.MonitorConfig
> org.apache.dubbo.config.ApplicationConfig
> org.apache.dubbo.config.ModuleConfig
> org.apache.dubbo.config.ProviderConfig
> org.apache.dubbo.config.ConsumerConfig
> org.apache.dubbo.config.MethodConfig
> org.apache.dubbo.config.ArgumentConfig

```java
package com.sihai.dubbo.consumer;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ReferenceConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.sihai.dubbo.provider.service.ProviderService;

/**
 * api的方式调用
 * api的方式调用不需要其他的配置，只需要下面的代码即可。
 * 但是需要注意，官方建议：
 * Api方式用于测试用例使用，推荐xml的方式
 */
public class AppApi {

    public static void main(String[] args) {
        // 当前应用配置
        ApplicationConfig application = new ApplicationConfig();
        application.setName("consumer");
        application.setOwner("sihai");

        // 连接注册中心配置
        RegistryConfig registry = new RegistryConfig();
        registry.setAddress("zookeeper://localhost:2181");

        // 注意：ReferenceConfig为重对象，内部封装了与注册中心的连接，以及与服务提供方的连接

        // 引用远程服务
        ReferenceConfig<ProviderService> reference = new ReferenceConfig<ProviderService>(); // 此实例很重，封装了与注册中心的连接以及与提供者的连接，请自行缓存，否则可能造成内存和连接泄漏
        reference.setApplication(application);
        reference.setRegistry(registry); // 多个注册中心可以用setRegistries()
        reference.setInterface(ProviderService.class);

        // 和本地bean一样使用xxxService
        ProviderService providerService = reference.get(); // 注意：此代理对象内部封装了所有通讯细节，对象较重，请缓存复用
        providerService.SayHello("hello dubbo! I am sihai!");
    }
}
```

#### 注解配置方式

```java
package com.sihai.dubbo.provider.service.annotation;

/**
 * 注解方式接口
 */
public interface ProviderServiceAnnotation {
    String SayHelloAnnotation(String word);
}
```

```java
package com.sihai.dubbo.provider.service.annotation;

import com.alibaba.dubbo.config.annotation.Service;

/**
 * 注解方式实现类
 */
@Service(timeout = 5000)
public class ProviderServiceImplAnnotation implements ProviderServiceAnnotation{

    public String SayHelloAnnotation(String word) {
        return word;
    }
}
```

```java
package com.sihai.dubbo.provider.configuration;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ProtocolConfig;
import com.alibaba.dubbo.config.ProviderConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

/**
 * 注解方式配置
 */
@Configuration
@EnableDubbo(scanBasePackages = "com.sihai.dubbo.provider.service.annotation")
public class DubboConfiguration {

    @Bean // #1 服务提供者信息配置
    public ProviderConfig providerConfig() {
        ProviderConfig providerConfig = new ProviderConfig();
        providerConfig.setTimeout(1000);
        return providerConfig;
    }

    @Bean // #2 分布式应用信息配置
    public ApplicationConfig applicationConfig() {
        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName("dubbo-annotation-provider");
        return applicationConfig;
    }

    @Bean // #3 注册中心信息配置
    public RegistryConfig registryConfig() {
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol("zookeeper");
        registryConfig.setAddress("localhost");
        registryConfig.setPort(2181);
        return registryConfig;
    }

    @Bean // #4 使用协议配置，这里使用 dubbo
    public ProtocolConfig protocolConfig() {
        ProtocolConfig protocolConfig = new ProtocolConfig();
        protocolConfig.setName("dubbo");
        protocolConfig.setPort(20880);
        return protocolConfig;
    }
}
```

```java
package com.sihai.dubbo.provider;

import com.alibaba.dubbo.config.spring.context.annotation.DubboComponentScan;
import com.sihai.dubbo.provider.configuration.DubboConfiguration;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import sun.applet.Main;

import java.io.IOException;

/**
 * 注解启动方式
 */
public class AppAnnotation {

    public static void main(String[] args) throws IOException {
        AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(DubboConfiguration.class); 
        context.start();
        System.in.read(); 
    }
}
```

```java
package com.sihai.dubbo.consumer.Annotation;

import com.alibaba.dubbo.config.annotation.Reference;
import com.sihai.dubbo.provider.service.annotation.ProviderServiceAnnotation;
import org.springframework.stereotype.Component;

/**
 * 注解方式的service
 */
@Component("annotatedConsumer")
public class ConsumerAnnotationService {

    @Reference
    private ProviderServiceAnnotation providerServiceAnnotation;

    public String doSayHello(String name) {
        return providerServiceAnnotation.SayHelloAnnotation(name);
    }
}
```

```java
package com.sihai.dubbo.consumer.configuration;

import com.alibaba.dubbo.config.ApplicationConfig;
import com.alibaba.dubbo.config.ConsumerConfig;
import com.alibaba.dubbo.config.RegistryConfig;
import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.ComponentScan;
import org.springframework.context.annotation.Configuration;

import java.util.HashMap;
import java.util.Map;

/**
 * 注解配置类
 */
@Configuration
@EnableDubbo(scanBasePackages = "com.sihai.dubbo.consumer.Annotation")
@ComponentScan(value = {"com.sihai.dubbo.consumer.Annotation"})
public class ConsumerConfiguration {
    @Bean // 应用配置
    public ApplicationConfig applicationConfig() {
        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName("dubbo-annotation-consumer");
        Map<String, String> stringStringMap = new HashMap<String, String>();
        stringStringMap.put("qos.enable","true");
        stringStringMap.put("qos.accept.foreign.ip","false");
        stringStringMap.put("qos.port","33333");
        applicationConfig.setParameters(stringStringMap);
        return applicationConfig;
    }

    @Bean // 服务消费者配置
    public ConsumerConfig consumerConfig() {
        ConsumerConfig consumerConfig = new ConsumerConfig();
        consumerConfig.setTimeout(3000);
        return consumerConfig;
    }

    @Bean // 配置注册中心
    public RegistryConfig registryConfig() {
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol("zookeeper");
        registryConfig.setAddress("localhost");
        registryConfig.setPort(2181);
        return registryConfig;
    }
}
```

```java
package com.sihai.dubbo.consumer;

import com.sihai.dubbo.consumer.Annotation.ConsumerAnnotationService;
import com.sihai.dubbo.consumer.configuration.ConsumerConfiguration;
import com.sihai.dubbo.provider.service.ProviderService;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

import java.io.IOException;

/**
 * 注解方式启动
 *
 */
public class AppAnnotation
{
    public static void main( String[] args ) throws IOException {

        AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ConsumerConfiguration.class); 
        context.start(); // 启动
        ConsumerAnnotationService consumerAnnotationService = context.getBean(ConsumerAnnotationService.class); 
        String hello = consumerAnnotationService.doSayHello("annotation"); // 调用方法
        System.out.println("result: " + hello); // 输出结果

    }
}
```

### 常用场景介绍

#### 启动时检查

Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 `check="true"。

```xml
<dubbo:registry protocol="zookeeper" address="localhost:2181,localhost:2182,localhost:2183" check="false"/>
```

```xml
<dubbo:reference check="false" id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"/>
```

#### 集群容错

| 集群模式          | 说明                                                         | 使用方法                                                 |
| ----------------- | ------------------------------------------------------------ | -------------------------------------------------------- |
| Failover Cluster  | 默认方案，失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数(不含第一次)。 | cluster="xxx" xxx：集群模式名称 ，例如cluster="failover" |
| Failfast Cluster  | 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 |                                                          |
| Failsafe Cluster  | 失败安全，出现异常时，直接忽略。                             |                                                          |
| Failback Cluster  | 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 |                                                          |
| Forking Cluster   | 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。 |                                                          |
| Broadcast Cluster | 广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 |                                                          |

```xml
<!--服务发布的配置，需要暴露的服务接口-->
    <dubbo:service cluster="failover" retries="2"
            interface="com.sihai.dubbo.provider.service.ProviderService"
            ref="providerService"/>
```

```xml
<dubbo:reference cluster="failover" retries="2" check="false" id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"/>
```

#### 负载均衡

| 负载均衡模式               | 说明                                                         | 使用方法                                             |
| -------------------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
| Random LoadBalance         | 随机 按权重设置随机概率                                      | <dubbo:service loadbalance="xxx"/> xxx：负载均衡方法 |
| RoundRobin LoadBalance     | 轮询 按公约后的权重设置轮询比率。                            |                                                      |
| LeastActive LoadBalance    | 最少活跃调用数 相同活跃数的随机，活跃数指调用前后计数差。    |                                                      |
| ConsistentHash LoadBalance | 一致性 Hash 相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 |                                                      |

#### 直连提供者

绕过注册中心，只测试指定服务提供者，只需要直接连接服务端的地即可。

```xml
<dubbo:reference id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"
                     url="dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService"/>
```

#### 只订阅

只订阅就是只能够订阅服务端的服务，而不能够注册。

可以让服务提供者开发方，只订阅服务(开发的服务可能依赖其它服务)，而不注册正在开发的服务，通过直连测试正在开发的服务。

```xml
<dubbo:registry register="false" protocol="zookeeper" address="localhost:2181,localhost:2182,localhost:2183" check="false"/>
```

```xml
<dubbo:reference cluster="failover" retries="2" check="false" id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService"/>
```

#### 只注册

可以向注册中心注册，但是，消费端却不能够读到服务。

如果有两个镜像环境，两个注册中心，有一个服务只在其中一个注册中心有部署，另一个注册中心还没来得及部署，而两个注册中心的其它应用都需要依赖此服务。这个时候，可以让服务提供者方只注册服务到另一注册中心，而不从另一注册中心订阅服务。

```xml
<dubbo:registry subscribe="false" address="localhost:2181"></dubbo:registry>
```

#### 多协议机制

**一种接口使用一种协议**

```xml
 <!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http-->
    <dubbo:protocol name="dubbo" port="20880"/>
    <dubbo:protocol name="rmi" port="1099" />

<!--服务发布的配置，需要暴露的服务接口-->
    <dubbo:service cluster="failover" retries="2"
            interface="com.sihai.dubbo.provider.service.ProviderService"
            ref="providerService"/>
    <dubbo:service cluster="failover" retries="2"
                   interface="com.sihai.dubbo.provider.service.ProviderService"
                   ref="providerService" protocol="rmi"/>
```

**一种接口使用多种协议**

```xml
<dubbo:service cluster="failover" retries="2"
                   interface="com.sihai.dubbo.provider.service.ProviderService"
                   ref="providerService" protocol="rmi,dubbo"/>
```

#### 多注册中心

```xml
<!--多注册中心-->
    <dubbo:registry protocol="zookeeper" id="reg1" timeout="10000" address="localhost:2181"/>
    <dubbo:registry protocol="zookeeper" id="reg2" timeout="10000" address="localhost:2182"/>
    <dubbo:registry protocol="zookeeper" id="reg3" timeout="10000" address="localhost:2183"/>

<!--服务发布的配置，需要暴露的服务接口-->
    <dubbo:service cluster="failover" retries="2"
            interface="com.sihai.dubbo.provider.service.ProviderService"
            ref="providerService" registry="reg1"/>
    <dubbo:service cluster="failover" retries="2"
                   interface="com.sihai.dubbo.provider.service.ProviderService"
                   ref="providerService" protocol="rmi" registry="reg2"/>
```

```xml
<!--多注册中心-->
    <dubbo:registry protocol="zookeeper" id="reg1" timeout="10000" address="localhost:2181"/>
    <dubbo:registry protocol="zookeeper" id="reg2" timeout="10000" address="localhost:2182"/>
    <dubbo:registry protocol="zookeeper" id="reg3" timeout="10000" address="localhost:2183"/>

!--不同的服务使用不同的注册中心-->
    <dubbo:reference cluster="failover" retries="2" check="false" id="providerService"
                     interface="com.sihai.dubbo.provider.service.ProviderService" registry="reg1"/>
    <dubbo:reference cluster="failover" retries="2" check="false" id="providerService2"
                     interface="com.sihai.dubbo.provider.service.ProviderService" registry="reg2"/>
```

#### 多版本

```xml
<!--不同的服务是有版本不同的，版本可以更新并且升级，同时，不同的版本之间是不可以调用的-->
<!--服务发布的配置，需要暴露的服务接口-->
    <dubbo:service cluster="failover" retries="2"
            interface="com.sihai.dubbo.provider.service.ProviderService"
            ref="providerService" registry="reg1" version="1.0.0"/>
    <dubbo:service cluster="failover" retries="2"
                   interface="com.sihai.dubbo.provider.service.ProviderService"
                   ref="providerService" protocol="rmi" registry="reg2" version="1.0.0"/>
```

#### 日志管理

dubbo 也可以将日志信息记录或者保存到文件中的。

- 使用accesslog输出到log4j

  ```xml
  <dubbo:protocol accesslog="true" name="dubbo" port="20880"/>
      <dubbo:protocol accesslog="true" name="rmi" port="1099" />
  ```

- 输出到文件

  ```xml
  <dubbo:protocol accesslog="http://localhost/log.txt" name="dubbo" port="20880"/>
      <dubbo:protocol accesslog="http://localhost/log2.txt" name="rmi" port="1099" />
  ```

## Zookeeper

Zookeeper 是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。Zookeeper 提供了一个类似于 Linux 文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制。

### Zookeeper角色

Zookeeper 集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种。

1. Leader

   一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader，它会发起并维护与各 Follwer及 Observer 间的心跳。所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。只要有超过半数节点（不包括 observeer 节点）写入成功，该写请求就会被提交（类 2PC 协议）。

2. Follower

   一个 Zookeeper 集群可能同时存在多个 Follower，它会响应 Leader 的心跳，Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票。

3. Observe

   角色与 Follower 类似，但是无投票权。Zookeeper 需保证高可用和强一致性，为了支持更多的客户端，需要增加更多 Server；Server 增多，投票阶段延迟增大，影响性能；引入 Observer，Observer 不参与投票； Observers 接受客户端的连接，并将写请求转发给 leader 节点； 加入更多 Observer 节点，提高伸缩性，同时不影响吞吐率。

![image-20230429210723889](分布式/image-20230429210723889.png)

### 投票机制

每个 sever 首先给自己投票，然后用自己的选票和其他 sever 选票对比，权重大的胜出，使用权重较大的更新自身选票箱。具体选举过程如下：
1. 每个 Server 启动以后都询问其它的 Server 它要投票给谁。对于其他 server 的询问，server 每次根据自己的状态都回复自己推荐的 leader 的 id 和上一次处理事务的 zxid（系统启动时每个 server 都会推荐自己）。
2. 收到所有 Server 回复以后，就计算出 zxid 最大的哪个 Server，并将这个 Server 相关信息设置成下一次要投票的 Server。
3. 计算这过程中获得票数最多的的 sever 为获胜者，如果获胜者的票数超过半数，则改server 被选为 leader。否则，继续这个过程，直到 leader 被选举出来。
4. leader 就会开始等待 server 连接。
5. Follower 连接 leader，将最大的 zxid 发送给 leader。
6. Leader 根据 follower 的 zxid 确定同步点，至此选举阶段完成。
7. 选举阶段完成 Leader 同步后通知 follower 已经成为 uptodate 状态。
8. Follower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了。

目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是 1,2,3,4,5,按编号依次启动，它们的选择举过程如下：
1. 服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器 1 的状态一直属于 Looking。
2. 服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
3. 服务器 3 启动，给自己投票，同时与之前启动的服务器 1,2 交换信息，由于服务器 3 的编号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器1,2 成为小弟。
4. 服务器 4 启动，给自己投票，同时与之前启动的服务器 1,2,3 交换信息，尽管服务器 4 的编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。
5. 服务器 5 启动，后面的逻辑同服务器 4 成为小弟。

### 工作原理（原子广播）

1. Zookeeper 的核心是原子广播，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式，它们分别是恢复模式和广播模式。

2. 当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 server 的完成了和 leader 的状态同步以后，恢复模式就结束了。
3. 状态同步保证了 leader 和 server 具有相同的系统状态
4. 一旦 leader 已经和多数的 follower 进行了状态同步后，他就可以开始广播消息了，即进入广播状态。这时候当一个 server 加入 zookeeper 服务中，它会在恢复模式下启动，发现 leader，并和 leader 进行状态同步。待到同步结束，它也参与消息广播。Zookeeper服务一直维持在 Broadcast 状态，直到 leader 崩溃了或者 leader 失去了大部分的followers 支持。
5. 广播模式需要保证 proposal 被按顺序处理，因此 zk 采用了递增的事务 id 号(zxid)来保证。所有的提议(proposal)都在被提出的时候加上了 zxid。
6. 实现中 zxid 是一个 64 为的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch。低 32 位是个递增计数。
7. 当 leader 崩溃或者 leader 失去大多数的 follower，这时候 zk 进入恢复模式，恢复模式需要重新选举出一个新的 leader，让所有的 server 都恢复到一个正确的状态。

### Znode四种形式的目录节点

1. PERSISTENT：持久的节点。
2. EPHEMERAL：暂时的节点。
3. PERSISTENT_SEQUENTIAL：持久化顺序编号目录节点。
4. EPHEMERAL_SEQUENTIAL：暂时化顺序编号目录节点。

## 一致性算法

### Paxos

Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。zookeeper 使用的 zab 算法是该算法的一个实现。 在 Paxos 算法中，有三种角色：Proposer，Acceptor，Learners。

**Paxos 三种角色：Proposer，Acceptor，Learners**

- Proposer：只要 Proposer 发的提案被半数以上 Acceptor 接受，Proposer 就认为该提案里的 value 被选定了。
- Acceptor：只要 Acceptor 接受了某个提案，Acceptor 就认为该提案里的 value 被选定了。
- Learners：Acceptor 告诉 Learner 哪个 value 被选定，Learner 就认为那个 value 被选定。

Paxos 算法分为两个阶段。具体如下：

阶段一（准 leader 确定 ）：

- Proposer 选择一个提案编号 N，然后向半数以上的 Acceptor  发送编号为 N 的 Prepare 请求。

- 如果一个 Acceptor 收到一个编号为 N 的 Prepare 请求，且 N 大于该 Acceptor 已经响应过的所有 Prepare 请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给 Proposer，同时该Acceptor 承诺不再接受任何编号小于 N 的提案。

阶段二（leader 确认）：

- 如果 Proposer 收到半数以上 Acceptor 对其发出的编号为 N 的 Prepare 请求的响应，那么它就会发送一个针对[N,V]提案的 Accept 请求给半数以上的 Acceptor。注意：V 就是收到的响应中编号最大的提案的 value，如果响应中不包含任何提案，那么 V 就由 Proposer 自己决定。
- 如果 Acceptor 收到一个针对编号为 N 的提案的 Accept 请求，只要该 Acceptor 没有对编号大于 N 的 Prepare 请求做出过响应，它就接受该提案。

### ZAB

#### Zxid（事务请求计数器+ epoch）

 在 ZAB ( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议） 协议的事务编号 Zxid 设计中，Zxid 是一个 64 位的数字，其中低 32 位是一个简单的单调递增的计数器，针对客户端每一个事务请求，计数器加 1；而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID，并从中读取epoch 值，然后加 1，以此作为新的 epoch，并将低 32 位从 0 开始计数。
Zxid（Transaction id）类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal（提议）ID。为了保证顺序性，该 zkid 必须单调递增。

#### epoch
epoch：可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后，也没有人听他的了，因为 follower 只听从当前年代的 leader 的命令。

#### 两种模式

Zab 协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。

#### ZAB 协议 4 阶段

**Leader election（选举阶段-选出准 Leader）**

1. Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。只有到达 广播阶段（broadcast） 准 leader 才会成为真正的 leader。这一阶段的目的是就是为了选出一个准 leader，然后进入下一个阶段。

**Discovery（发现阶段-接受提议、生成 epoch、接受 epoch）**

2. Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议，并且准 leader 生成新的 epoch，让 followers 接受，更新它们的 accepted Epoch

  一个 follower 只会连接一个 leader，如果有一个节点 f 认为另一个 follower p 是 leader，f 在尝试连接 p 时会被拒绝，f 被拒绝之后，就会进入重新选举阶段。

**Synchronization（同步阶段-同步 follower 副本）**

3. Synchronization（同步阶段）：同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。只有当 大多数节点都同步完成，准 leader 才会成为真正的 leader。
follower 只会接收 zxid 比自己的 lastZxid 大的提议。

**Broadcast（广播阶段-leader 消息广播）**

4. Broadcast（广播阶段）：到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。
ZAB 提交事务并不像 2PC 一样需要全部 follower 都 ACK，只需要得到超过半数的节点的 ACK 就可以了。

**ZAB 协议 JAVA 实现（FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段））**
协议的 Java 版本实现跟上面的定义有些不同，选举阶段使用的是 Fast Leader Election（FLE），它包含了 选举的发现职责。因为 FLE 会选举拥有最新提议历史的节点作为 leader，这样就省去了发现最新提议的步骤。实际的实现将 发现阶段 和 同步合并为 Recovery Phase（恢复阶段）。所以，ZAB 的实现只有三个阶段：Fast Leader Election；Recovery Phase；Broadcast Phase。

### Raft

与 Paxos 不同 Raft 强调的是易懂（Understandability），Raft 和 Paxos 一样只要保证 n/2+1 节点正常就能够提供服务；raft 把算法流程分为三个子问题：选举（Leader election）、日志复制（Log replication）、安全性（Safety）三个子问题。

#### 角色

Raft 把集群中的节点分为三种状态：Leader、 Follower 、Candidate，理所当然每种状态负责的任务也是不一样的，Raft 运行时提供服务的时候只存在 Leader 与 Follower 两种状态；

##### Leader领导者-日志管理

负责日志的同步管理，处理来自客户端的请求，与 Follower 保持这 heartBeat 的联系；

##### Follower追随者-日志同步

刚启动时所有节点为Follower状态，响应Leader的日志同步请求，响应Candidate的请求，把请求到 Follower 的事务转发给 Leader；

##### Candidate候选者-负责选票

负责选举投票，Raft 刚启动时由一个节点从 Follower 转为 Candidate 发起选举，选举出Leader 后从 Candidate 转为 Leader 状态；

#### Term任期

在 Raft 中使用了一个可以理解为周期（第几届、任期）的概念，用 Term 作为一个周期，每个 Term 都是一个连续递增的编号，每一轮选举都是一个 Term 周期，在一个 Term 中只能产生一个 Leader；当某节点收到的请求中 Term 比当前 Term 小时则拒绝该请求。

#### 选举Election

**选举定时器**

Raft 的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为Follower 某个节点定时器触发选举后 Term 递增，状态由 Follower 转为 Candidate，向其他节点发起 RequestVote RPC 请求，这时候有三种可能的情况发生：

1. 该 RequestVote 请求接收到 n/2+1（过半数）个节点的投票，从 Candidate 转为 Leader，
   向其他节点发送 heartBeat 以保持 Leader 的正常运转。

2. 在此期间如果收到其他节点发送过来的 AppendEntries RPC 请求，如该节点的 Term 大则当前节点转为 Follower，否则保持 Candidate 拒绝该请求。

3. Election timeout 发生则 Term 递增，重新发起选举在一个 Term 期间每个节点只能投票一次，所以当有多个 Candidate 存在时就会出现每个Candidate 发起的选举都存在接收到的投票数都不过半的问题，这时每个 Candidate 都将 Term递增、重启定时器并重新发起选举，由于每个节点中定时器的时间都是随机的，所以就不会多次存在有多个 Candidate 同时发起投票的问题。

在 Raft 中当接收到客户端的日志（事务请求）后先把该日志追加到本地的 Log 中，然后通过heartbeat 把该 Entry 同步给其他 Follower，Follower 接收到日志后记录日志然后向 Leader 发送ACK，当 Leader 收到大多数（n/2+1）Follower 的 ACK 信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个 heartbeat 中 Leader 将通知所有的 Follower 将该日志存储在自己的本地磁盘中。

#### 安全性

安全性是用于保证每个节点都执行相同序列的安全机制如当某个 Follower 在当前 Leader commit Log 时变得不可用了，稍后可能该 Follower 又会倍选举为 Leader，这时新 Leader 可能会用新的Log 覆盖先前已 committed 的 Log，这就是导致节点执行不同序列；Safety 就是用于保证选举出来的 Leader 一定包含先前 commited Log 的机制；

选举安全性（Election Safety）：每个 Term 只能选举出一个 Leader

Leader 完整性（Leader Completeness）：这里所说的完整性是指 Leader 日志的完整性，Raft 在选举阶段就使用 Term 的判断用于保证完整性：当请求投票的该 Candidate 的 Term 较大或 Term 相同 Index 更大则投票，该节点将容易变成 leader。

### NWR

N： 在分布式存储系统中，有多少份备份数据
W：代表一次成功的更新操作要求至少有 w 份数据写入成功
R： 代表一次成功的读数据操作要求至少有 R 份数据成功读取
NWR值的不同组合会产生不同的一致性效果，当W+R>N 的时候，整个系统对于客户端来讲能保证强一致性。而如果 R+W<=N，则无法保证数据的强一致性。以常见的 N=3、W=2、R=2 为例：
N=3，表示，任何一个对象都必须有三个副本（Replica），W=2 表示，对数据的修改操作（Write）只需要在 3 个 Replica 中的 2 个上面完成就返回，R=2 表示，从三个对象中要读取到 2个数据对象，才能返回。

### Gossip

Gossip 算法又被称为反熵（Anti-Entropy），熵是物理学上的一个概念，代表杂乱无章，而反熵就是在杂乱无章中寻求一致，这充分说明了 Gossip 的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的

### 一致性Hash

一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n 个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。

简单的说，一致性哈希是将整个哈希值空间组织成一个虚拟的圆环，如假设哈希函数H的值空间为0-2^32-1（哈希值是32位无符号整形），整个哈希空间环如下：

![哈希环](分布式/1460000017847101.png)

整个空间按顺时针方向组织，0和2^32-1在零点中方向重合。

接下来，把服务器按照IP或主机名作为关键字进行哈希，这样就能确定其在哈希环的位置。

![哈希环2](分布式/1460000017847102.png)

然后，我们就可以使用哈希函数H计算值为key的数据在哈希环的具体位置h，根据h确定在环中的具体位置，从此位置沿顺时针滚动，遇到的第一台服务器就是其应该定位到的服务器。

例如我们有A、B、C、D四个数据对象，经过哈希计算后，在环空间上的位置如下：

![哈希环3](分布式/1460000017847103.png)

假如RedisService2宕机了，那么，数据B对应的节点保存到RedisService3中。因此，其中一台宕机后，干扰的只有前面的数据（原数据被保存到顺时针的下一个服务器），而不会干扰到其他的数据。

假如增加一台服务器Redis4，具体位置如下图所示：

![RedisServicee4](分布式/1460000017847105.png)

原本数据C是保存到Redis3中，但由于增加了Redis4，数据C被保存到Redis4中。干扰的也只有Redis3而已，其他数据不会受到影响。

因此，一致性哈希算法对于节点的增减都只需重定位换空间的一小部分即可，具有较好的容错性和可扩展性。

如果节点较少就会出现节点分布不均衡造成数据倾斜问题。

例如，我们的的系统有两台Redis，分布的环位置如下图所示：

![哈希环](分布式/1460000017847106.png)

这会产生一种情况，Redis4的hash范围比Redis3的hash范围大，导致数据大部分都存储在Redis4中，数据存储不平衡。

为了解决这种数据存储不平衡的问题，一致性哈希算法引入了**虚拟节点机制**，即对每个节点计算多个哈希值，每个计算结果位置都放置在对应节点中，这些节点称为**虚拟节点**。

具体做法可以在服务器IP或主机名的后面增加编号来实现，例如上面的情况，可以为每个服务节点增加三个虚拟节点，于是可以分为 RedisService1#1、 RedisService1#2、 RedisService1#3、 RedisService2#1、 RedisService2#2、 RedisService2#3，具体位置如下图所示：

![虚拟节点](分布式/1460000017847107.png)

对于数据定位的hash算法仍然不变，只是增加了虚拟节点到实际节点的映射。例如，数据C保存到虚拟节点Redis1#2，实际上数据保存到Redis1中。这样，就能解决服务节点少时数据不平均的问题。在实际应用中，通常将虚拟节点数设置为**32甚至更大**，因此即使**很少的服务节点**也能做到相对**均匀的数据分布**。

## 分布式锁

### Redis

#### 基于Redis实现分布式锁

```shell
// 获取锁
// NX是指如果key不存在就成功，key存在返回false，PX可以指定过期时间
SET anyLock unique_value NX PX 30000
```

```lua
// 释放锁：通过执行一段lua脚本
// 释放锁涉及到两条指令，这两条指令不是原子性的
// 需要用到redis的lua脚本支持特性，redis执行lua脚本是原子性的
if redis.call("get",KEYS[1]) == ARGV[1] then
return redis.call("del",KEYS[1])
else
return 0
end
```

- 原子性操作，避免key永久存在
- value要具有唯一性，避免锁被误删

使用redis做分布式锁的缺点在于：如果采用单机部署模式，会存在单点问题，只要redis故障了。加锁就不行了。

采用master-slave模式，加锁的时候只对一个节点加锁，即便通过sentinel做了高可用，但是如果master节点故障了，发生主从切换，此时就会有可能出现锁丢失的问题。

#### RedLock

假设redis的部署模式是redis cluster，总共有5个master节点，通过以下步骤获取一把锁：

- 获取当前时间戳，单位是毫秒

- 轮流尝试在每个master节点上创建锁，过期时间设置较短，一般就几十毫秒

- 尝试在大多数节点上建立一个锁，比如5个节点就要求是3个节点（n / 2 +1）

- 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了

- 要是锁建立失败了，那么就依次删除这个锁

- 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁

但是这样的这种算法还是颇具争议的，可能还会存在不少的问题，无法保证加锁的过程一定正确。

#### Redisson

```java
Config config = new Config();
config.useClusterServers()
.addNodeAddress("redis://192.168.31.101:7001")
.addNodeAddress("redis://192.168.31.101:7002")
.addNodeAddress("redis://192.168.31.101:7003")
.addNodeAddress("redis://192.168.31.102:7001")
.addNodeAddress("redis://192.168.31.102:7002")
.addNodeAddress("redis://192.168.31.102:7003");
 
RedissonClient redisson = Redisson.create(config);
 
 
RLock lock = redisson.getLock("anyLock");
lock.lock();
lock.unlock();

RLock lock1 = redisson.getFairLock("lock1");
RLock lock2 = redisson.getFairLock("lock2");
RLock lock3 = redisson.getFairLock("lock3");
RedissonRedLock multiLock = new RedissonRedLock(lock1, lock2, lock3);
multiLock.lock();
multiLock.unlock();
```

redisson所有指令都通过lua脚本执行，redis支持lua脚本原子性执行

redisson设置一个key的默认过期时间为30s,如果某个客户端持有一个锁超过了30s怎么办？

redisson中有一个watchdog的概念，翻译过来就是看门狗，它会在你获取锁之后，每隔10秒帮你把key的超时时间设为30s

这样的话，就算一直持有锁也不会出现key过期了，其他线程获取到锁的问题了。

redisson的“看门狗”逻辑保证了没有死锁发生。

(如果机器宕机了，看门狗也就没了。此时就不会延长key的过期时间，到了30s之后就会自动过期了，其他线程可以获取到锁)

**Redisson实现代码**

```java
// 加锁逻辑
private <T> RFuture<Long> tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) {
    if (leaseTime != -1) {
        return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);
    }
    // 调用一段lua脚本，设置一些key、过期时间
    RFuture<Long> ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);
    ttlRemainingFuture.addListener(new FutureListener<Long>() {
        @Override
        public void operationComplete(Future<Long> future) throws Exception {
            if (!future.isSuccess()) {
                return;
            }
 
            Long ttlRemaining = future.getNow();
            // lock acquired
            if (ttlRemaining == null) {
                // 看门狗逻辑
                scheduleExpirationRenewal(threadId);
            }
        }
    });
    return ttlRemainingFuture;
}
 
 
<T> RFuture<T> tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {
    internalLockLeaseTime = unit.toMillis(leaseTime);
 
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
              "if (redis.call('exists', KEYS[1]) == 0) then " +
                  "redis.call('hset', KEYS[1], ARGV[2], 1); " +
                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                  "return nil; " +
              "end; " +
              "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
                  "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                  "return nil; " +
              "end; " +
              "return redis.call('pttl', KEYS[1]);",
                Collections.<Object>singletonList(getName()), internalLockLeaseTime, getLockName(threadId));
}
 
 
 
// 看门狗最终会调用了这里
private void scheduleExpirationRenewal(final long threadId) {
    if (expirationRenewalMap.containsKey(getEntryName())) {
        return;
    }
 
    // 这个任务会延迟10s执行
    Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() {
        @Override
        public void run(Timeout timeout) throws Exception {
 
            // 这个操作会将key的过期时间重新设置为30s
            RFuture<Boolean> future = renewExpirationAsync(threadId);
 
            future.addListener(new FutureListener<Boolean>() {
                @Override
                public void operationComplete(Future<Boolean> future) throws Exception {
                    expirationRenewalMap.remove(getEntryName());
                    if (!future.isSuccess()) {
                        log.error("Can't update lock " + getName() + " expiration", future.cause());
                        return;
                    }
 
                    if (future.getNow()) {
                        // reschedule itself
                        // 通过递归调用本方法，无限循环延长过期时间
                        scheduleExpirationRenewal(threadId);
                    }
                }
            });
        }
 
    }, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS);
 
    if (expirationRenewalMap.putIfAbsent(getEntryName(), new ExpirationEntry(threadId, task)) != null) {
        task.cancel();
    }
}
```

### Zookeeper

#### 基于zookeeper实现分布式锁

zookeeper包含一系列的节点，叫做znode，就好像文件系统一样每个znode表示一个目录，然后znode有一些特性：

- 有序节点：假如当前有一个父节点为/lock，我们可以在这个父节点下面创建子节点；
  zookeeper提供了一个可选的有序特性，例如我们可以创建子节点“/lock/node-”并且指明有序，那么zookeeper在生成子节点时会根据当前的子节点数量自动添加整数序号
  也就是说，如果是第一个创建的子节点，那么生成的子节点为/lock/node-0000000000，下一个节点则为/lock/node-0000000001，依次类推。
- 临时节点：客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点。
- 事件监听：在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。当前zookeeper有如下四种事件：
  - 节点创建
  - 节点删除
  - 节点数据修改
  - 子节点变更

使用zk实现分布式锁的落地方案：

1. 使用zk的临时节点和有序节点，每个线程获取锁就是在zk创建一个临时有序的节点，比如在/lock/目录下。

2. 创建节点成功后，获取/lock目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点

3. 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。

4. 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。

比如当前线程获取到的节点序号为/lock/003,然后所有的节点列表为[/lock/001,/lock/002,/lock/003],则对/lock/002这个节点添加一个事件监听器。

如果锁释放了，会唤醒下一个序号的节点，然后重新执行第3步，判断是否自己的节点序号是最小。

比如/lock/001释放了，/lock/002监听到时间，此时节点集合为[/lock/002,/lock/003],则/lock/002为最小序号节点，获取到锁。

![img](分布式/format1png.png)

#### Curator

Curator是一个zookeeper的开源客户端，也提供了分布式锁的实现。

```java
InterProcessMutex interProcessMutex = new InterProcessMutex(client,"/anyLock");
interProcessMutex.acquire();
interProcessMutex.release();
```

![img](分布式/format2png.png)

### MySQL

## 分布式事务

### 认识分布式事务

![image-20230430233012838](分布式/image-20230430233012838.png)

#### CAP

- ⼀致性(Consistency) ： 客户端知道⼀系列的操作都会同时发⽣(⽣效)

- 可用性(Availability) ： 每个操作都必须以可预期的响应结束

- 分区容错性(Partition tolerance) ： 即使出现单个组件⽆法可用，操作依然可以完成

具体地讲在分布式系统中，⼀个Web应用⾄多只能同时⽀持上⾯的两个属性。因此，设计⼈员必须在⼀致性与可用性之间做出选择。

##### 一致性

**数据⼀致性分为强⼀致性、弱⼀致性、最终⼀致性**。

- 如果的确能像上⾯描述的那样时刻保证客户端看到的数据都是⼀致的，那么称之为强⼀致性。
- 如果允许存在中间状态，只要求经过⼀段时间后，数据最终是⼀致的，则称之为最终⼀致性。
- 此外，如果允许存在部分数据不⼀致，那么就称之为弱⼀致性。

##### 可用性

系统提供的服务必须⼀直处于可用的状态，对于用户的每⼀个操作请求总是能够在有限的时间内返回结果。

1. 有限时间内

   对于用户的⼀个操作请求，系统必须能够在指定的时间（响应时间）内返回对应的处理结果，**如果超过了这个时间范围，那么系统就被认为是不可用的**。即这个响应时间必须在⼀个合理的值内，不让用户感到失望。

2. 返回正常结果

   要求系统在完成对用户请求的处理后，返回⼀个正常的响应结果。正常的响应结果通常能够明确地反映出对请求的处理结果，即成功或失败，而不是⼀个让用户感到困惑的返回结果。

##### 分区容错性

即分布式系统在遇到任何⽹络分区故障时，仍然需要能够保证对外提供满足⼀致性和可用性的服务，除非是整个网络环境都发⽣了故障。

网络分区，是指分布式系统中，不同的节点分布在不同的子网络（机房/异地网络）中，由于⼀些特殊的原因导致这些子网络之间出现网络不连通的状态，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干孤立的区域。组成⼀个分布式系统的每个节点的加⼊与退出都可以看做是⼀个特殊的网络分区。

#### BASE

1. Basically Available（基本可⽤）
   1. 响应时间上的损失
   2. 功能上的损失
2. Soft state（软状态）
   与硬状态相对，即是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可⽤性，即允许系统在不同节点的数据副本之间进⾏数据同步的过程存在延时。
3. Eventually consistent（最终⼀致性）
   强调系统中所有的数据副本，在经过⼀段时间的同步后，最终能够达到⼀个⼀致的状态。其本质是需要系统保证最终数据能够达到⼀致，⽽不需要实时保证系统数据的强⼀致性。
   1. 因果⼀致性（Causal consistency）：即进程A在更新完数据后通知进程B，那么之后进程B对该项数据的范围都是进程A更新后的最新值。
   2. 读⼰之所写（Read your writes）：进程A更新⼀项数据后，它⾃⼰总是能访问到⾃⼰更新过的最新值。
   3. 会话⼀致性（Session consistency）：将数据⼀致性框定在会话当中，在⼀个会话当中实现读⼰之所写的⼀致性。即执⾏更新后，客户端在同⼀个会话中始终能读到该项数据的最新值
   4. 单调读⼀致性（Monotonic read consistency）：如果⼀个进程从系统中读取出⼀个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。
   5. 单调写⼀致性（Monotoic write consistency）：⼀个系统需要保证来⾃同⼀个进程的写操作被顺序执⾏。

#### 2PC

![image-20230430235121833](分布式/image-20230430235121833.png)

![image-20230430235154132](分布式/image-20230430235154132.png)

#### 3PC

![image-20230430235219856](分布式/image-20230430235219856.png)

![image-20230430235242126](分布式/image-20230430235242126.png)

#### MQ事务消息方案

![image-20230430235325262](分布式/image-20230430235325262.png)

#### 本地消息方案

![image-20230430235417150](分布式/image-20230430235417150.png)

#### TCC

![image-20230430235524023](分布式/image-20230430235524023.png)

#### SAGA

![image-20230430235609836](分布式/image-20230430235609836.png)

#### 各大模式总体对比

|            | 2PC  | TCC  | Saga | 异步确保型事务 | 尽最大努力通知 |
| ---------- | ---- | ---- | ---- | -------------- | -------------- |
| 事务一致性 | 强   | 弱   | 弱   | 弱             | 弱             |
| 复杂性     | 中   | 高   | 中   | 低             | 低             |
| 业务侵入性 | 小   | 大   | 小   | 中             | 中             |
| 使用局限性 | 大   | 大   | 中   | 小             | 中             |
| 性能       | 低   | 中   | 高   | 高             | 高             |
| 维护成本   | 低   | 高   | 中   | 低             | 中             |

### 分布式事务解决方案Seata

#### Seata AT

![image-20230430233510943](分布式/image-20230430233510943.png)

#### Seata TCC

![image-20230430233546960](分布式/image-20230430233546960.png)

#### Seata Saga

![image-20230430233604315](分布式/image-20230430233604315.png)

#### Seata XA

XA 模式需要 XAConnection。

从编程模型上，XA 模式与 AT 模式保持完全⼀致。
